{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Computer Vision Applications](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Computer Vision Applications](#toc1_)    \n",
    "  - [Object Detection](#toc1_1_)    \n",
    "    - [Object Detection with Faster R-CNN](#toc1_1_1_)    \n",
    "  - [Image Segmentation](#toc1_2_)    \n",
    "    - [Image Segmentation with Detectron2](#toc1_2_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (0.20.1)\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.5-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: filelock in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from albumentations) (1.13.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from albumentations) (2.10.4)\n",
      "Collecting albucore==0.0.23 (from albumentations)\n",
      "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting eval-type-backport (from albumentations)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations)\n",
      "  Downloading stringzilla-3.12.2-cp39-cp39-win_amd64.whl.metadata (81 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\n",
      "  Downloading simsimd-6.2.1-cp39-cp39-win_amd64.whl.metadata (67 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.27.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sabinafirtala\\anaconda3\\envs\\cv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading albumentations-2.0.5-py3-none-any.whl (290 kB)\n",
      "Downloading albucore-0.0.23-py3-none-any.whl (14 kB)\n",
      "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-win_amd64.whl (39.4 MB)\n",
      "   ---------------------------------------- 0.0/39.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/39.4 MB 7.4 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 2.9/39.4 MB 7.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 4.5/39.4 MB 7.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 5.5/39.4 MB 7.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.3/39.4 MB 7.2 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 8.9/39.4 MB 7.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 10.5/39.4 MB 7.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 12.1/39.4 MB 7.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 13.6/39.4 MB 7.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 14.9/39.4 MB 7.2 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 16.5/39.4 MB 7.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 18.1/39.4 MB 7.3 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 19.4/39.4 MB 7.1 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 21.2/39.4 MB 7.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 22.8/39.4 MB 7.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 24.4/39.4 MB 7.3 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 26.0/39.4 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.5/39.4 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 29.1/39.4 MB 7.3 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.7/39.4 MB 7.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 32.2/39.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.8/39.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.4/39.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 37.0/39.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/39.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.4 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.4/39.4 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading simsimd-6.2.1-cp39-cp39-win_amd64.whl (86 kB)\n",
      "Downloading stringzilla-3.12.2-cp39-cp39-win_amd64.whl (80 kB)\n",
      "Installing collected packages: stringzilla, simsimd, opencv-python-headless, eval-type-backport, albucore, albumentations\n",
      "Successfully installed albucore-0.0.23 albumentations-2.0.5 eval-type-backport-0.2.2 opencv-python-headless-4.11.0.86 simsimd-6.2.1 stringzilla-3.12.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'git+https://github.com/facebookresearch/detectron2.git'\": Expected package name at the start of dependency specifier\n",
      "    'git+https://github.com/facebookresearch/detectron2.git'\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision albumentations opencv-python\n",
    "!pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    return transform(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Object Detection](#toc0_)\n",
    "Object detection is a computer vision technique that identifies and localizes objects within an image. Unlike image classification, which assigns a single label to an image, object detection provides bounding boxes around detected objects. Common object detection models include YOLO (You Only Look Once), SSD (Single Shot MultiBox Detector), and Faster R-CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Object Detection with Faster R-CNN](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(image_path):\n",
    "    \"\"\"Performs object detection on an image using Faster R-CNN.\"\"\"\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    model.eval()\n",
    "    \n",
    "    image_tensor = load_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image_tensor)\n",
    "    \n",
    "    # Display the image with bounding boxes\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    for i, box in enumerate(prediction[0]['boxes']):\n",
    "        x1, y1, x2, y2 = map(int, box.numpy())\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Image Segmentation](#toc0_)\n",
    "Image segmentation is the process of partitioning an image into multiple regions to identify objects more precisely at the pixel level. There are two main types:\n",
    "- **Semantic Segmentation**: Classifies each pixel in an image into a category (e.g., sky, car, road).\n",
    "- **Instance Segmentation**: Distinguishes between individual objects of the same class (e.g., two different cars in an image). Models like U-Net and Mask R-CNN are commonly used for segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Image Segmentation with Detectron2](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Detectron2 is Facebook AI Research's next generation library that provides state-of-the-art detection and segmentation algorithms. It is the successor of Detectron and maskrcnn-benchmark. It supports a number of computer vision research projects and production applications in Facebook. *(Source: [Facebook GitHub](https://github.com/facebookresearch/detectron2))*\n",
    "\n",
    "![](../../../../img/detectron2.png)  \n",
    "(Source: [Facebook GitHub](https://github.com/facebookresearch/detectron2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_segmentation(image_path):\n",
    "    \"\"\"Performs instance segmentation on an image using Detectron2's Mask R-CNN.\"\"\"\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    outputs = predictor(image)\n",
    "    \n",
    "    # Display segmented mask\n",
    "    v = outputs['instances'].pred_masks.cpu().numpy()\n",
    "    plt.imshow(v[0], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
