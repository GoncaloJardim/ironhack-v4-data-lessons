{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Building LLM Agents](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Building LLM Agents](#toc1_)    \n",
    "  - [Introduction to LLM Agents](#toc1_1_)    \n",
    "    - [What Are LLM Agents?](#toc1_1_1_)    \n",
    "    - [How Do LLM Agents Work?](#toc1_1_2_)    \n",
    "  - [Building a Basic LLM Agent with OpenAI](#toc1_2_)    \n",
    "  - [Enhancing LLM Agents with LangChain](#toc1_3_)    \n",
    "  - [Multi-Agent Systems with LangGraph](#toc1_4_)    \n",
    "    - [What's a DAG?](#toc1_4_1_)    \n",
    "      - [Graph](#toc1_4_1_1_)    \n",
    "      - [Acyclic](#toc1_4_1_2_)    \n",
    "      - [Directed](#toc1_4_1_3_)    \n",
    "    - [Where else are DAGs used?](#toc1_4_2_)    \n",
    "    - [Why Are DAGs Important for LLM Agents?](#toc1_4_3_)    \n",
    "    - [Building our own DAG - a simple multi-agent system](#toc1_4_4_)    \n",
    "  - [Types of LLM Agents](#toc1_5_)    \n",
    "    - [Web Scraping Agent](#toc1_5_1_)    \n",
    "    - [Web Search Agent](#toc1_5_2_)    \n",
    "    - [Retrieval-Augmented Generation (RAG) Agent](#toc1_5_3_)    \n",
    "    - [Tool-Using Agent](#toc1_5_4_)    \n",
    "  - [Putting it all together](#toc1_6_)    \n",
    "  - [Conclusion](#toc1_7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Introduction to LLM Agents](#toc0_)\n",
    "\n",
    "### <a id='toc1_1_1_'></a>[What Are LLM Agents?](#toc0_)\n",
    "Large Language Model (LLM) agents are AI-powered entities that use natural language processing to interact with users, perform tasks, and automate workflows. These agents leverage models like OpenAIâ€™s GPT to process and generate human-like text responses.\n",
    "\n",
    "### <a id='toc1_1_2_'></a>[How Do LLM Agents Work?](#toc0_)\n",
    "LLM agents typically function by:\n",
    "1. **Receiving Input**: Users provide prompts or queries.\n",
    "2. **Processing Input**: The agent structures the input and passes it to the LLM.\n",
    "3. **Generating Output**: The LLM formulates a response based on context.\n",
    "4. **Executing Actions**: If necessary, the agent can integrate with external tools to perform tasks beyond text generation.\n",
    "\n",
    "## <a id='toc1_2_'></a>[Building a Basic LLM Agent with OpenAI](#toc0_)\n",
    "Ensure you have the OpenAI Python library installed and use a `.env` file to set up your API key (`OPENAI_API_KEY`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up your API key and define a simple LLM agent function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Define a simple LLM agent function\n",
    "def llm_agent(prompt, model=\"gpt-4\"):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Enhancing LLM Agents with LangChain](#toc0_)\n",
    "LangChain is a powerful framework for building LLM-powered applications with memory, tools, and agentic capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-4\")\n",
    "prompt = PromptTemplate(input_variables=[\"question\"], template=\"Answer the following: {question}\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print(chain.run(\"What is LangChain?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Multi-Agent Systems with LangGraph](#toc0_)\n",
    "LangGraph extends LangChain by enabling multi-agent interactions through DAGs (Directed Acyclic Graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[What's a DAG?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Directed Acyclic Graph (DAG)** is a graph structure where nodes are connected by directed edges, and there are no cycles. This means that information flows in one direction without looping back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_1_'></a>[Graph](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **graph** is a data structure consisting of nodes (or vertices) connected by edges. Graphs are widely used in computer science, mathematics, and AI to model relationships between entities.\n",
    "\n",
    "![](../../../img/graph_edge_matrix.png)  \n",
    "(Source: [HuggingFace](http://huggingface.co/blog/intro-graphml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_2_'></a>[Acyclic](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cyclic vs. Acyclic Graphs**: A cyclic graph has cycles, whereas an acyclic graph does not.  \n",
    "\n",
    "![](../../../img/a_cyclical_graphs.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_3_'></a>[Directed](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directed Graphs**: Edges have a specific direction (A â†’ B).  \n",
    "\n",
    "![](../../../img/directed-graph.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[Where else are DAGs used?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../img/airflow_dag.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAGs are widely used in streamlining data/ML operations that need to happen sequentially and at regular time intervals. Airflow is one of the most basic platforms where you can build this type of pipelines and monitor the success/failure of your pipelines. You can also schedule runs of pipelines, connect to cloud services, etc. Other schedulers used by data scientists are Prefect (recommended), Dask (for large-scale data processing), Kubeflow pipelines (can be overkill), DAGster. \n",
    "\n",
    "You'd do have to do some research before choosing any of these - Airflow is always a good starting point as it's open-source - but users complain that it's outdated compared to competitors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[Why Are DAGs Important for LLM Agents?](#toc0_)\n",
    "- **Task Execution Flow**: DAGs define clear steps in multi-agent workflows.\n",
    "- **Parallel Processing**: Independent tasks can run simultaneously.\n",
    "- **Dependency Management**: Ensures tasks execute in the correct order.\n",
    "\n",
    "LangGraph uses DAGs to structure multi-agent workflows, ensuring efficient and logical task progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_4_'></a>[Building our own DAG - a simple multi-agent system](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import Message\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def agent_1(state):\n",
    "    response = ChatOpenAI().predict(\"Provide an initial analysis on AI safety.\")\n",
    "    return Message(response)\n",
    "\n",
    "def agent_2(state):\n",
    "    response = ChatOpenAI().predict(f\"Expand on the following: {state['message']}\")\n",
    "    return Message(response)\n",
    "\n",
    "workflow = StateGraph()\n",
    "workflow.add_nodes([\"agent_1\", \"agent_2\"])\n",
    "workflow.add_edges([(\"agent_1\", \"agent_2\")])\n",
    "workflow.set_entry_point(\"agent_1\")\n",
    "workflow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Types of LLM Agents](#toc0_)\n",
    "LLM agents can be categorized based on their purpose and capabilities. Below are some common types with code examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_1_'></a>[Web Scraping Agent](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def web_agent(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return text[:500]  # Return a snippet\n",
    "\n",
    "print(web_agent(\"https://en.wikipedia.org/wiki/Artificial_intelligence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_2_'></a>[Web Search Agent](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_3_'></a>[Retrieval-Augmented Generation (RAG) Agent](#toc0_)\n",
    "Uses vector databases for enhanced responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def rag_agent(query, stored_vectors):\n",
    "    index = faiss.IndexFlatL2(stored_vectors.shape[1])\n",
    "    index.add(stored_vectors)\n",
    "    query_vector = np.random.random((1, stored_vectors.shape[1])).astype('float32')\n",
    "    distances, indices = index.search(query_vector, k=3)\n",
    "    return indices\n",
    "\n",
    "stored_vectors = np.random.random((10, 128)).astype('float32')\n",
    "print(rag_agent(\"What is machine learning?\", stored_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_4_'></a>[Tool-Using Agent](#toc0_)\n",
    "An agent that integrates with APIs or tools (e.g., calculator, weather API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def weather_agent(city):\n",
    "    api_key = \"your_api_key_here\"\n",
    "    url = f\"http://api.weatherapi.com/v1/current.json?key={api_key}&q={city}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()[\"current\"][\"temp_c\"]\n",
    "\n",
    "print(weather_agent(\"New York\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Putting it all together](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import Message\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def agent_1(state):\n",
    "    response = ChatOpenAI().predict(\"Summarize the latest AI research.\")\n",
    "    return Message(response)\n",
    "\n",
    "def agent_2(state):\n",
    "    response = ChatOpenAI().predict(f\"Expand on this summary: {state['message']}\")\n",
    "    return Message(response)\n",
    "\n",
    "workflow = StateGraph()\n",
    "workflow.add_nodes([\"agent_1\", \"agent_2\"])\n",
    "workflow.add_edges([(\"agent_1\", \"agent_2\")])\n",
    "workflow.set_entry_point(\"agent_1\")\n",
    "workflow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Conclusion](#toc0_)\n",
    "- **LLM agents** enable intelligent text-based automation.\n",
    "- **LangChain** enhances LLMs with tools, memory, and structured pipelines.\n",
    "- **LangGraph** facilitates multi-agent workflows for complex AI interactions.\n",
    "\n",
    "With these tools, you can build powerful AI-driven applications. ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lizzy_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
