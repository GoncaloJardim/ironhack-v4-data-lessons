{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Building LLM Agents - Red Cross Helpful Information as Aid](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Building LLM Agents](#toc1_)    \n",
    "  - [Introduction to LLM Agents](#toc1_1_)    \n",
    "    - [What Are LLM Agents?](#toc1_1_1_)    \n",
    "    - [How Do LLM Agents Work?](#toc1_1_2_)    \n",
    "  - [Building a Basic LLM Agent with OpenAI](#toc1_2_)    \n",
    "  - [Enhancing LLM Agents with LangChain](#toc1_3_)    \n",
    "  - [Multi-Agent Systems with LangGraph](#toc1_4_)    \n",
    "    - [What's a DAG?](#toc1_4_1_)    \n",
    "      - [Graph](#toc1_4_1_1_)    \n",
    "      - [Acyclic](#toc1_4_1_2_)    \n",
    "      - [Directed](#toc1_4_1_3_)    \n",
    "    - [Where else are DAGs used?](#toc1_4_2_)    \n",
    "    - [Why Are DAGs Important for LLM Agents?](#toc1_4_3_)    \n",
    "    - [Building our own DAG - a simple multi-agent system](#toc1_4_4_)    \n",
    "  - [Types of LLM Agents](#toc1_5_)    \n",
    "    - [Web Scraping Agent](#toc1_5_1_)    \n",
    "    - [Web Search Agent](#toc1_5_2_)    \n",
    "    - [Retrieval-Augmented Generation (RAG) Agent](#toc1_5_3_)    \n",
    "    - [Tool-Using Agent](#toc1_5_4_)    \n",
    "  - [Putting it all together](#toc1_6_)    \n",
    "  - [Conclusion](#toc1_7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Introduction to LLM Agents](#toc0_)\n",
    "\n",
    "### <a id='toc1_1_1_'></a>[What Are LLM Agents?](#toc0_)\n",
    "> Agents are systems that use LLMs as **reasoning engines** to determine which actions to take and the inputs necessary to perform the action. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. This is often achieved via tool-calling. *(Source: [LangChain](https://python.langchain.com/docs/tutorials/agents/))*\n",
    "\n",
    "### <a id='toc1_1_2_'></a>[How Do LLM Agents Work?](#toc0_)\n",
    "Just like any other LLM. The only difference is that based on the constraints we put on LLM agents (e.g. prompt, structured output), we are able to get them to fulfill a specific role without further model finetuning. An LLM agent typically sits within a pipeline of LLM agents, like we see in [this example](https://langchain-mrkl.streamlit.app/?ref=streamlit-io-gallery-llms). \n",
    "\n",
    "## <a id='toc1_2_'></a>[Building a Basic LLM Agent with OpenAI](#toc0_)\n",
    "Ensure you have the OpenAI Python library installed and use a `.env` file to set up your API key (`OPENAI_API_KEY`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up your API key and define a simple LLM agent function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history_1 = [{\"role\": \"system\", \"content\": \"You are a helpful assistant\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "\n",
    "def llm_agent(input_, message_history, model=\"gpt-3.5-turbo\"):\n",
    "    llm = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    message_history.append({\"role\": \"user\", \"content\": f\"{input_}\"})\n",
    "\n",
    "    # Generate a response from the chatbot model\n",
    "    completion = llm.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=message_history\n",
    "    )\n",
    "\n",
    "    # We save the assistant response\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "    return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent(\"I am hungry\", message_history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is not inherently a bad reply, it doesn't provide any specific support right away. So during this lesson, we'll try to make this better, bit by bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = [\n",
    "    \"Shelter\",\n",
    "    \"Health & Wellbeing\",\n",
    "    \"Safety & Protection\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_cross_assistant_prompt = \"\"\"You are an expert query analyzer for a Red Cross virtual assistant.\n",
    "    Analyze the query to understand the user's needs, emotional state, and language.\n",
    "    Pay special attention to any signs of emergency or urgent needs.\n",
    "\n",
    "    If you detect any of these, mark as EMERGENCY:\n",
    "    - Immediate danger\n",
    "    - Medical emergencies \n",
    "    - Severe distress\n",
    "    - Threats to basic safety\n",
    "\n",
    "    If the query is unclear, you should return relevant domains from this list as clarification options:\n",
    "    {}\n",
    "\n",
    "    Important: You will analyze:\n",
    "    1. Query clarity and type (clear/needs_clarification/emergency)\n",
    "    2. Domains of need, from this list of options {} or \"Other\"\n",
    "    3. Emotional state from language and content\n",
    "    4. Language of query\n",
    "    \"\"\".format(domain_list, domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history_2 = [{\"role\": \"system\", \"content\": red_cross_assistant_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent(\"I am hungry\", message_history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the issue with this is that it doesn't provide any useful information, it just asks clarifying questions. But that's ok, we can create an LLM with..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from typing_extensions import Union\n",
    "from pydantic import BaseModel # pydantic is a data validation library widely used in the industry\n",
    "\n",
    "Domains = Literal[\n",
    "    \"Shelter\",\n",
    "    \"Health & Wellbeing\",\n",
    "    \"Safety & Protection\",\n",
    "]\n",
    "DomainWithOther = Union[Domains, Literal[\"Other\"]]\n",
    "\n",
    "class QueryAnalysis(BaseModel):\n",
    "    \"\"\"Analysis output from Query Understanding Agent\"\"\"\n",
    "    query_type: Literal[\"clear\", \"needs_clarification\", \"emergency\"]\n",
    "    domains: List[DomainWithOther]\n",
    "    emotional_state: str\n",
    "    language: str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_agent(input_, message_history, model=\"gpt-4o-2024-08-06\"):\n",
    "    llm = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    message_history.append({\"role\": \"user\", \"content\": f\"{input_}\"})\n",
    "\n",
    "    # Generate a response from the chatbot model\n",
    "    completion = llm.beta.chat.completions.parse(\n",
    "      model=model,\n",
    "      messages=message_history,\n",
    "      response_format=QueryAnalysis\n",
    "    )\n",
    "\n",
    "    # We save the assistant response\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "    return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent(\"I am hungry\", message_history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! We've already created a useful AI agent. However, if we wanted to switch to a different provider, e.g. Anthropic, or use an open-source LLM, e.g. Llama, DeepSeek, we would need to change our code completely! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Enhancing LLM Agents with LangChain](#toc0_)\n",
    "\n",
    "With LangChain, we can use a lot more models without changing our code each time we change an LLM. Additionally, LangChain is able to couple multiple agents together, allowing an LLM to answer more complex queries more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain_community\n",
    "# !pip install -U langchain-openai\n",
    "!pip install langchain-ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\")\n",
    "response = llm.invoke(message_history_1)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(message_history_2)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.with_structured_output(QueryAnalysis).invoke(message_history_2)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I was able to do the exact same thing with significantly fewer lines of code! Now let's see what other agents we can play with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Multi-Agent Systems with LangGraph](#toc0_)\n",
    "Although we can already build a multi-agent system with LangChain, we have one constraint: the sequence of actions can only be linear. LangGraph extends LangChain by enabling parallel/conditional interactions through DAGs (Directed Acyclic Graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[What's a DAG?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Directed Acyclic Graph (DAG)** is a graph structure where nodes are connected by directed edges, and there are no cycles. This means that information flows in one direction without looping back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_1_'></a>[Graph](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **graph** is a data structure consisting of nodes (or vertices) connected by edges. Graphs are widely used in computer science, mathematics, and AI to model relationships between entities.\n",
    "\n",
    "![](../../../img/graph_edge_matrix.png)  \n",
    "(Source: [HuggingFace](http://huggingface.co/blog/intro-graphml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_2_'></a>[Acyclic](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cyclic vs. Acyclic Graphs**: A cyclic graph has cycles, whereas an acyclic graph does not.  \n",
    "\n",
    "![](../../../img/a_cyclical_graphs.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_3_'></a>[Directed](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directed Graphs**: Edges have a specific direction (A → B).  \n",
    "\n",
    "![](../../../img/directed-graph.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[Where else are DAGs used?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../img/airflow_dag.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAGs are widely used in streamlining data/ML operations that need to happen sequentially and at regular time intervals. Airflow is one of the most basic platforms where you can build this type of pipelines and monitor the success/failure of your pipelines. You can also schedule runs of pipelines, connect to cloud services, etc. Other schedulers used by data scientists are Prefect (recommended), Dask (for large-scale data processing), Kubeflow pipelines (can be overkill), DAGster. \n",
    "\n",
    "You'd do have to do some research before choosing any of these - Airflow is always a good starting point as it's open-source, but users complain that it's outdated compared to competitors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[Why Are DAGs Important for LLM Agents?](#toc0_)\n",
    "- **Task Execution Flow**: DAGs define clear steps in multi-agent workflows.\n",
    "- **Parallel Processing**: Independent tasks can run simultaneously.\n",
    "- **Dependency Management**: Ensures tasks execute in the correct order.\n",
    "\n",
    "LangGraph uses DAGs to structure multi-agent workflows, ensuring efficient and logical task progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_4_'></a>[Building our own DAG - a simple multi-agent system](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import Message\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def query_understanding(state):\n",
    "    response = ChatOpenAI().predict(\"Provide an initial analysis on AI safety.\")\n",
    "    return Message(response)\n",
    "\n",
    "def agent_2(state):\n",
    "    response = ChatOpenAI().predict(f\"Expand on the following: {state['message']}\")\n",
    "    return Message(response)\n",
    "\n",
    "workflow = StateGraph()\n",
    "workflow.add_nodes([\"agent_1\", \"agent_2\"])\n",
    "workflow.add_edges([(\"agent_1\", \"agent_2\")])\n",
    "workflow.set_entry_point(\"agent_1\")\n",
    "workflow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Types of LLM Agents](#toc0_)\n",
    "LLM agents can be categorized based on their purpose and capabilities. Below are some common types with code examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_1_'></a>[Web Scraping Agent](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def web_agent(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    return text[:500]  # Return a snippet\n",
    "\n",
    "print(web_agent(\"https://en.wikipedia.org/wiki/Artificial_intelligence\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_2_'></a>[Web Search Agent](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_3_'></a>[Retrieval-Augmented Generation (RAG) Agent](#toc0_)\n",
    "Uses vector databases for enhanced responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def rag_agent(query, stored_vectors):\n",
    "    index = faiss.IndexFlatL2(stored_vectors.shape[1])\n",
    "    index.add(stored_vectors)\n",
    "    query_vector = np.random.random((1, stored_vectors.shape[1])).astype('float32')\n",
    "    distances, indices = index.search(query_vector, k=3)\n",
    "    return indices\n",
    "\n",
    "stored_vectors = np.random.random((10, 128)).astype('float32')\n",
    "print(rag_agent(\"What is machine learning?\", stored_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_4_'></a>[Tool-Using Agent](#toc0_)\n",
    "An agent that integrates with APIs or tools (e.g., calculator, weather API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def weather_agent(city):\n",
    "    api_key = \"your_api_key_here\"\n",
    "    url = f\"http://api.weatherapi.com/v1/current.json?key={api_key}&q={city}\"\n",
    "    response = requests.get(url)\n",
    "    return response.json()[\"current\"][\"temp_c\"]\n",
    "\n",
    "print(weather_agent(\"New York\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Putting it all together](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import Message\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def agent_1(state):\n",
    "    response = ChatOpenAI().predict(\"Summarize the latest AI research.\")\n",
    "    return Message(response)\n",
    "\n",
    "def agent_2(state):\n",
    "    response = ChatOpenAI().predict(f\"Expand on this summary: {state['message']}\")\n",
    "    return Message(response)\n",
    "\n",
    "workflow = StateGraph()\n",
    "workflow.add_nodes([\"agent_1\", \"agent_2\"])\n",
    "workflow.add_edges([(\"agent_1\", \"agent_2\")])\n",
    "workflow.set_entry_point(\"agent_1\")\n",
    "workflow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Conclusion](#toc0_)\n",
    "- **LLM agents** enable intelligent text-based automation.\n",
    "- **LangChain** enhances LLMs with tools, memory, and structured pipelines.\n",
    "- **LangGraph** facilitates multi-agent workflows for complex AI interactions.\n",
    "\n",
    "With these tools, you can build powerful AI-driven applications. 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lizzy_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
