{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Building LLM Agents - Red Cross Helpful Information as Aid](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Building LLM Agents - Red Cross Helpful Information as Aid](#toc1_)    \n",
    "  - [Introduction to LLM Agents](#toc1_1_)    \n",
    "    - [What Are LLM Agents?](#toc1_1_1_)    \n",
    "    - [How Do LLM Agents Work?](#toc1_1_2_)    \n",
    "  - [Building a Basic LLM Agent with OpenAI](#toc1_2_)    \n",
    "    - [Prompt Engineering](#toc1_2_1_)    \n",
    "    - [Structured Output](#toc1_2_2_)    \n",
    "  - [Enhancing LLM Agents with LangChain](#toc1_3_)    \n",
    "    - [Simple Agent](#toc1_3_1_)    \n",
    "    - [Web Search Agent](#toc1_3_2_)    \n",
    "  - [Multi-Agent Systems with LangGraph](#toc1_4_)    \n",
    "    - [What's a DAG?](#toc1_4_1_)    \n",
    "      - [Graph](#toc1_4_1_1_)    \n",
    "      - [Acyclic](#toc1_4_1_2_)    \n",
    "      - [Directed](#toc1_4_1_3_)    \n",
    "    - [Where else are DAGs used?](#toc1_4_2_)    \n",
    "    - [Why Are DAGs Important for LLM Agents?](#toc1_4_3_)    \n",
    "    - [Building our own DAG - a simple multi-agent system](#toc1_4_4_)    \n",
    "  - [Conclusion](#toc1_5_)    \n",
    "- [Extra](#toc2_)    \n",
    "  - [Tool-Using Agent](#toc2_1_)    \n",
    "  - [RAG Agent](#toc2_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Introduction to LLM Agents](#toc0_)\n",
    "\n",
    "### <a id='toc1_1_1_'></a>[What Are LLM Agents?](#toc0_)\n",
    "> Agents are systems that use LLMs as **reasoning engines** to determine which actions to take and the inputs necessary to perform the action. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. This is often achieved via tool-calling. *(Source: [LangChain](https://python.langchain.com/docs/tutorials/agents/))*\n",
    "\n",
    "### <a id='toc1_1_2_'></a>[How Do LLM Agents Work?](#toc0_)\n",
    "Just like any other LLM. The only difference is that based on the constraints we put on LLM agents (e.g. prompt, structured output), we are able to get them to fulfill a specific role without further model finetuning. An LLM agent typically sits within a pipeline of LLM agents, like we see in [this example](https://langchain-mrkl.streamlit.app/?ref=streamlit-io-gallery-llms). \n",
    "\n",
    "## <a id='toc1_2_'></a>[Building a Basic LLM Agent with OpenAI](#toc0_)\n",
    "Ensure you have the OpenAI Python library installed and use a `.env` file to set up your API key (`OPENAI_API_KEY`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up your API key and define a simple LLM agent function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history_1 = [{\"role\": \"system\", \"content\": \"You are a helpful assistant\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "from pprint import pprint\n",
    "\n",
    "def llm_agent(input_, message_history, model=\"gpt-3.5-turbo\"):\n",
    "    llm = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    message_history.append({\"role\": \"user\", \"content\": f\"{input_}\"})\n",
    "\n",
    "    # Generate a response from the chatbot model\n",
    "    completion = llm.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=message_history\n",
    "    )\n",
    "\n",
    "    # We save the assistant response\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "    return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant', 'role': 'system'},\n",
      " {'content': 'I am hungry', 'role': 'user'},\n",
      " {'content': 'I can help you find a recipe to make a meal at home, suggest '\n",
      "             'nearby restaurants for takeout or delivery, or recommend snack '\n",
      "             \"ideas you may have on hand. Just let me know what you're in the \"\n",
      "             'mood for!',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(llm_agent(\"I am hungry\", message_history_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is not inherently a bad reply, it doesn't provide any specific support right away. So during this lesson, we'll try to make this better, bit by bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Prompt Engineering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll aim to improve our assistant and reproduce a small part of [HIA (Helpful Information as Aid)](https://github.com/sabinagio/HIA) - a multi-agent solution for the Red Cross 510 data team:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = [\n",
    "    \"Shelter\",\n",
    "    \"Health & Wellbeing\",\n",
    "    \"Safety & Protection\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_cross_assistant_prompt = \"\"\"You are an expert query analyzer for a Red Cross virtual assistant.\n",
    "    Analyze the query to understand the user's needs, emotional state, and language.\n",
    "    Pay special attention to any signs of emergency or urgent needs.\n",
    "\n",
    "    If you detect any of these, mark as EMERGENCY:\n",
    "    - Immediate danger\n",
    "    - Medical emergencies \n",
    "    - Severe distress\n",
    "    - Threats to basic safety\n",
    "\n",
    "    If the query is unclear, you should return relevant domains from this list as clarification options:\n",
    "    {}\n",
    "\n",
    "    Important: You will analyze:\n",
    "    1. Query clarity and type (clear/needs_clarification/emergency)\n",
    "    2. Domains of need, from this list of options {} or \"Other\"\n",
    "    3. Emotional state from language and content\n",
    "    4. Language of query\n",
    "    \"\"\".format(domain_list, domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history_2 = [{\"role\": \"system\", \"content\": red_cross_assistant_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are an expert query analyzer for a Red Cross virtual '\n",
      "             'assistant.\\n'\n",
      "             \"    Analyze the query to understand the user's needs, emotional \"\n",
      "             'state, and language.\\n'\n",
      "             '    Pay special attention to any signs of emergency or urgent '\n",
      "             'needs.\\n'\n",
      "             '\\n'\n",
      "             '    If you detect any of these, mark as EMERGENCY:\\n'\n",
      "             '    - Immediate danger\\n'\n",
      "             '    - Medical emergencies \\n'\n",
      "             '    - Severe distress\\n'\n",
      "             '    - Threats to basic safety\\n'\n",
      "             '\\n'\n",
      "             '    If the query is unclear, you should return relevant domains '\n",
      "             'from this list as clarification options:\\n'\n",
      "             \"    ['Shelter', 'Health & Wellbeing', 'Safety & Protection']\\n\"\n",
      "             '\\n'\n",
      "             '    Important: You will analyze:\\n'\n",
      "             '    1. Query clarity and type '\n",
      "             '(clear/needs_clarification/emergency)\\n'\n",
      "             \"    2. Domains of need, from this list of options ['Shelter', \"\n",
      "             '\\'Health & Wellbeing\\', \\'Safety & Protection\\'] or \"Other\"\\n'\n",
      "             '    3. Emotional state from language and content\\n'\n",
      "             '    4. Language of query\\n'\n",
      "             '    ',\n",
      "  'role': 'system'},\n",
      " {'content': 'I am hungry', 'role': 'user'},\n",
      " {'content': '1. Query clarity and type: Clear\\n'\n",
      "             '2. Domains of need: Health & Wellbeing\\n'\n",
      "             '3. Emotional state: Hungry (basic need)\\n'\n",
      "             '4. Language of query: Neutral\\n'\n",
      "             '\\n'\n",
      "             'This query is a clear indication of a basic need for food '\n",
      "             '(Health & Wellbeing domain). There are no signs of emergency or '\n",
      "             'urgency.',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(llm_agent(\"I am hungry\", message_history_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the issue with this is that it doesn't provide any useful information, it just asks clarifying questions. But that's ok, we can create an LLM with..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[Structured Output](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from typing_extensions import Union\n",
    "from pydantic import BaseModel # pydantic is a data validation library widely used in the industry\n",
    "\n",
    "Domains = Literal[\n",
    "    \"Shelter\",\n",
    "    \"Health & Wellbeing\",\n",
    "    \"Safety & Protection\",\n",
    "]\n",
    "DomainWithOther = Union[Domains, Literal[\"Other\"]]\n",
    "\n",
    "class QueryAnalysis(BaseModel):\n",
    "    \"\"\"Analysis output from Query Understanding Agent\"\"\"\n",
    "    original_query: str\n",
    "    query_type: Literal[\"clear\", \"emergency\"]\n",
    "    domains: List[DomainWithOther]\n",
    "    emotional_state: str\n",
    "    language: str \n",
    "\n",
    "# QueryAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_agent(input_, message_history, model=\"gpt-4o-2024-08-06\"):\n",
    "    llm = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    message_history.append({\"role\": \"user\", \"content\": f\"{input_}\"})\n",
    "\n",
    "    # Generate a response from the chatbot model\n",
    "    completion = llm.beta.chat.completions.parse(\n",
    "      model=model,\n",
    "      messages=message_history,\n",
    "      response_format=QueryAnalysis\n",
    "    )\n",
    "\n",
    "    # We save the assistant response\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "    return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are an expert query analyzer for a Red Cross virtual '\n",
      "             'assistant.\\n'\n",
      "             \"    Analyze the query to understand the user's needs, emotional \"\n",
      "             'state, and language.\\n'\n",
      "             '    Pay special attention to any signs of emergency or urgent '\n",
      "             'needs.\\n'\n",
      "             '\\n'\n",
      "             '    If you detect any of these, mark as EMERGENCY:\\n'\n",
      "             '    - Immediate danger\\n'\n",
      "             '    - Medical emergencies \\n'\n",
      "             '    - Severe distress\\n'\n",
      "             '    - Threats to basic safety\\n'\n",
      "             '\\n'\n",
      "             '    If the query is unclear, you should return relevant domains '\n",
      "             'from this list as clarification options:\\n'\n",
      "             \"    ['Shelter', 'Health & Wellbeing', 'Safety & Protection']\\n\"\n",
      "             '\\n'\n",
      "             '    Important: You will analyze:\\n'\n",
      "             '    1. Query clarity and type '\n",
      "             '(clear/needs_clarification/emergency)\\n'\n",
      "             \"    2. Domains of need, from this list of options ['Shelter', \"\n",
      "             '\\'Health & Wellbeing\\', \\'Safety & Protection\\'] or \"Other\"\\n'\n",
      "             '    3. Emotional state from language and content\\n'\n",
      "             '    4. Language of query\\n'\n",
      "             '    ',\n",
      "  'role': 'system'},\n",
      " {'content': 'I am hungry', 'role': 'user'},\n",
      " {'content': '1. Query clarity and type: Clear\\n'\n",
      "             '2. Domains of need: Health & Wellbeing\\n'\n",
      "             '3. Emotional state: Hungry (basic need)\\n'\n",
      "             '4. Language of query: Neutral\\n'\n",
      "             '\\n'\n",
      "             'This query is a clear indication of a basic need for food '\n",
      "             '(Health & Wellbeing domain). There are no signs of emergency or '\n",
      "             'urgency.',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'I am hungry', 'role': 'user'},\n",
      " {'content': '{\"original_query\":\"I am '\n",
      "             'hungry\",\"query_type\":\"clear\",\"domains\":[\"Health & '\n",
      "             'Wellbeing\"],\"emotional_state\":\"Basic need for '\n",
      "             'food\",\"language\":\"English\"}',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(llm_agent(\"I am hungry\", message_history_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"original_query\":\"I am hungry\",\"query_type\":\"clear\",\"domains\":[\"Health & Wellbeing\"],\"emotional_state\":\"Basic need for food\",\"language\":\"English\"}'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history_2[-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are an expert query analyzer for a Red Cross virtual '\n",
      "             'assistant.\\n'\n",
      "             \"    Analyze the query to understand the user's needs, emotional \"\n",
      "             'state, and language.\\n'\n",
      "             '    Pay special attention to any signs of emergency or urgent '\n",
      "             'needs.\\n'\n",
      "             '\\n'\n",
      "             '    If you detect any of these, mark as EMERGENCY:\\n'\n",
      "             '    - Immediate danger\\n'\n",
      "             '    - Medical emergencies \\n'\n",
      "             '    - Severe distress\\n'\n",
      "             '    - Threats to basic safety\\n'\n",
      "             '\\n'\n",
      "             '    If the query is unclear, you should return relevant domains '\n",
      "             'from this list as clarification options:\\n'\n",
      "             \"    ['Shelter', 'Health & Wellbeing', 'Safety & Protection']\\n\"\n",
      "             '\\n'\n",
      "             '    Important: You will analyze:\\n'\n",
      "             '    1. Query clarity and type '\n",
      "             '(clear/needs_clarification/emergency)\\n'\n",
      "             \"    2. Domains of need, from this list of options ['Shelter', \"\n",
      "             '\\'Health & Wellbeing\\', \\'Safety & Protection\\'] or \"Other\"\\n'\n",
      "             '    3. Emotional state from language and content\\n'\n",
      "             '    4. Language of query\\n'\n",
      "             '    ',\n",
      "  'role': 'system'},\n",
      " {'content': 'I am hungry', 'role': 'user'},\n",
      " {'content': '1. Query clarity and type: Clear\\n'\n",
      "             '2. Domains of need: Health & Wellbeing\\n'\n",
      "             '3. Emotional state: Hungry (basic need)\\n'\n",
      "             '4. Language of query: Neutral\\n'\n",
      "             '\\n'\n",
      "             'This query is a clear indication of a basic need for food '\n",
      "             '(Health & Wellbeing domain). There are no signs of emergency or '\n",
      "             'urgency.',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'I am hungry', 'role': 'user'},\n",
      " {'content': '{\"original_query\":\"I am '\n",
      "             'hungry\",\"query_type\":\"clear\",\"domains\":[\"Health & '\n",
      "             'Wellbeing\"],\"emotional_state\":\"Basic need for '\n",
      "             'food\",\"language\":\"English\"}',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'I have nowhere to sleep', 'role': 'user'},\n",
      " {'content': '{\"original_query\":\"I have nowhere to '\n",
      "             'sleep\",\"query_type\":\"emergency\",\"domains\":[\"Shelter\"],\"emotional_state\":\"Distressed\",\"language\":\"English\"}',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(llm_agent(\"I have nowhere to sleep\", message_history_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! We've already created a useful AI agent. However, if we wanted to switch to a different provider, e.g. Anthropic, or use an open-source LLM, e.g. Llama, DeepSeek, we would need to change our code completely! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Enhancing LLM Agents with LangChain](#toc0_)\n",
    "\n",
    "With LangChain, we can use a lot more models without changing our code each time we change an LLM. Additionally, LangChain is able to couple multiple agents together, allowing an LLM to answer more complex queries more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain_community\n",
    "# !pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Simple Agent](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='What type of cuisine are you interested in?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 68, 'total_tokens': 78, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-688b7563-fd73-45e9-9e8b-5eef5f418b6f-0', usage_metadata={'input_tokens': 68, 'output_tokens': 10, 'total_tokens': 78, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\")\n",
    "response = llm.invoke(message_history_1)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='1. Query clarity and type: Emergency\\n2. Domains of need: Shelter\\n3. Emotional state: Distressed\\n4. Language of query: English\\n\\nThis query indicates an urgent need for shelter (Shelter domain) and the user seems to be in distress.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 369, 'total_tokens': 426, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-35b624f0-ad88-4064-83c7-c27deb0c4ff8-0', usage_metadata={'input_tokens': 369, 'output_tokens': 57, 'total_tokens': 426, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(message_history_2)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SabinaFirtala\\anaconda3\\envs\\lizzy_nlp\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryAnalysis(original_query='I have nowhere to sleep', query_type='emergency', domains=['Shelter'], emotional_state='Distressed', language='English')\n"
     ]
    }
   ],
   "source": [
    "response = llm.with_structured_output(QueryAnalysis).invoke(message_history_2)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have nowhere to sleep'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.original_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emergency'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.query_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I was able to do the exact same thing with significantly fewer lines of code! Now let's see what other agents we can play with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Web Search Agent](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "def web_search(query: str) -> dict:\n",
    "    wrapper = DuckDuckGoSearchAPIWrapper(region=\"nl-nl\", max_results=2) # time='y' limit to past year (m, d, w)\n",
    "    search_tool = DuckDuckGoSearchResults(api_wrapper=wrapper)\n",
    "    return search_tool.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('snippet: The expression \"Ik heb honger\" is a common and neutral way to say '\n",
      " '\"I\\'m hungry\" in both formal and casual contexts. There are no specific '\n",
      " 'expressions that make the translation formal or casual in this context., '\n",
      " 'title: How do you say \"i\\'m hungry \" in Dutch? | HiNative, link: '\n",
      " 'https://hinative.com/questions/26523530, snippet: Waking up hungry is more '\n",
      " \"than just a cue that you're ready for breakfast. Three experts on the \"\n",
      " \"reasons you're waking up hungry and what it says about your health., title: \"\n",
      " '8 Reasons You May Be Waking Up Hungry, According to Experts - TODAY, link: '\n",
      " 'https://www.today.com/health/health/waking-up-hungry-rcna192814, snippet: '\n",
      " 'Feeling hungry but lacking appetite can be frustrating. Learn the causes, '\n",
      " 'from medical conditions to mental health, and discover tips to regain your '\n",
      " 'desire to eat. For New Providers, title: Hungry, but No Appetite: Why it '\n",
      " 'Happens & What to Do | Season, link: '\n",
      " 'https://www.seasonhealth.com/blog/why-do-you-feel-hungry-but-dont-want-to-eat, '\n",
      " 'snippet: Explore the reasons why you might still feel hungry after eating '\n",
      " 'and discover actionable tips to promote fullness and manage hunger '\n",
      " 'effectively., title: Stomach Feel Empty After Eating? 6 Possible Reasons Why '\n",
      " '| Season, link: '\n",
      " 'https://www.seasonhealth.com/blog/why-does-my-stomach-feel-empty-after-eating')\n"
     ]
    }
   ],
   "source": [
    "pprint(web_search(\"I am hungry\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can search stuff on the internet now. Let's see how we can combine this with our previous agent to get a better search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    Create a simple search query (maximum 10 words) in English \n",
    "    that will help find relevant assistance information.\n",
    "    Return ONLY the search query, no explanation or strategy.\n",
    "    \"\"\"\n",
    "\n",
    "domain_sites = {\n",
    "        \"food\": [\"voedselbank.nl\", \"voedselbankennederland.nl\"],\n",
    "        \"shelter\": [\"deregenboog.org\", \"opvang.nl\"],\n",
    "        \"healthcare\": [\"ggd.nl\", \"zorgverzekeringslijn.nl\"],\n",
    "        \"domestic_violence\": [\"veiligthuis.nl\", \"blijfgroep.nl\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_search_query(query: QueryAnalysis, domains=domain_sites, prompt=system_prompt):\n",
    "    # Prepare relevant websites\n",
    "    relevant_sites = [\"rodekruis.nl\"]\n",
    "    if query.domains:\n",
    "        for domain in domains:\n",
    "            if domain.lower() in domain_sites:\n",
    "                relevant_sites.extend(domain_sites[domain.lower()])\n",
    "\n",
    "    # Generate search query using LLM\n",
    "    llm = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\")\n",
    "    search_query_response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Original query: {query.original_query}\n",
    "            Language: {query.language}\n",
    "            Domains: {query.domains or 'Not specified'}\n",
    "        \"\"\"}\n",
    "    ])\n",
    "    print(\"This is the LLM query search response:\")\n",
    "    pprint(search_query_response)\n",
    "    search_query = search_query_response.content\n",
    "    domain_priority = \" OR \".join(f\"site:{site}\" for site in relevant_sites)\n",
    "    return f\"{search_query} {domain_priority}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SabinaFirtala\\anaconda3\\envs\\lizzy_nlp\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryAnalysis(original_query='I am hungry', query_type='clear', domains=['Health & Wellbeing'], emotional_state='Neutral', language='English')\n"
     ]
    }
   ],
   "source": [
    "response = llm.with_structured_output(QueryAnalysis).invoke([\n",
    "        {\"role\": \"system\", \"content\": red_cross_assistant_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"I am hungry\"},\n",
    "    ]\n",
    ")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the LLM query search response:\n",
      "AIMessage(content='How to find food assistance nearby.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 74, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e06f96d4-596d-4f02-867c-cff3f3e5ef9b-0', usage_metadata={'input_tokens': 74, 'output_tokens': 8, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "('snippet: Je bent welkom. Heb je even geen geld om eten te kopen? Geen '\n",
      " 'zorgen. Dat kan iedereen overkomen. Wanneer kom ik in aanmerking? Als je je '\n",
      " 'aanmeldt, krijg je meteen boodschappen mee. Dat doen we minimaal voor een '\n",
      " 'maand. Ondertussen bespreken en bekijken we de hele papierwinkel binnen drie '\n",
      " 'maanden na je aanmelding. We kijken […], title: Kom ik in aanmerking? - '\n",
      " 'Vereniging van Voedselbanken Nederland, link: '\n",
      " 'https://voedselbankennederland.nl/ik-zoek-hulp/kom-ik-in-aanmerking/, '\n",
      " 'snippet: Jij kunt dan ook een enorme bijdrage leveren aan het helpen van '\n",
      " 'meer mensen. Zoals in het eerste artikel van deze Vitamine te lezen, heb je '\n",
      " 'daarmee niet alleen impact op een gezin maar op de hele samenleving. '\n",
      " 'Bovendien is het een enorme stimulans voor onze 14.000 vrijwilligers. Het '\n",
      " 'werk dat ze doen is letterlijk […], title: Voor € 25,- help je een gezin een '\n",
      " 'hele maand - Vereniging van ..., link: '\n",
      " 'https://voedselbankennederland.nl/voor-e25-per-maand-help-je-een-gezin-aan-een-voedselpakket/, '\n",
      " 'snippet: Een brandwond of vergiftiging, bewusteloos raken of iets kneuzen. '\n",
      " 'Een ongeluk kan zomaar gebeuren. Met de gratis EHBO-app van het Rode Kruis '\n",
      " 'weet je altijd en overal wat je moet doen., title: Altijd EHBO-hulp binnen '\n",
      " 'handbereik met de Rode Kruis-app, link: '\n",
      " 'https://www.rodekruis.nl/nieuwsbericht/altijd-ehbo-hulp-binnen-handbereik-met-de-rode-kruis-app/, '\n",
      " 'snippet: Tijdens de algemene ledenvergadering van de vereniging van '\n",
      " 'Nederlandse Voedselbanken op 30 november hebben de Nederlandse Voedselbanken '\n",
      " 'de waarden en normen rond de toekenningscriteria per 1 januari 2025 '\n",
      " 'vastgesteld., title: Criteria Voedselbanken nog meer afgestemd op ambitie om '\n",
      " 'meer mensen te ..., link: '\n",
      " 'https://voedselbankennederland.nl/criteria-voedselbanken-nog-meer-afgestemd-op-ambitie-om-meer-mensen-te-helpen/')\n"
     ]
    }
   ],
   "source": [
    "web_response = web_search(build_search_query(response))\n",
    "pprint(web_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Multi-Agent Systems with LangGraph](#toc0_)\n",
    "Although we can already build a multi-agent system with LangChain, we have one constraint: the sequence of actions can only be linear. LangGraph extends LangChain by enabling parallel/conditional interactions through DAGs (Directed Acyclic Graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[What's a DAG?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Directed Acyclic Graph (DAG)** is a graph structure where nodes are connected by directed edges, and there are no cycles. This means that information flows in one direction without looping back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_1_'></a>[Graph](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **graph** is a data structure consisting of nodes (or vertices) connected by edges. Graphs are widely used in computer science, mathematics, and AI to model relationships between entities.\n",
    "\n",
    "![](../../../img/graph_edge_matrix.png)  \n",
    "(Source: [HuggingFace](http://huggingface.co/blog/intro-graphml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_2_'></a>[Acyclic](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cyclic vs. Acyclic Graphs**: A cyclic graph has cycles, whereas an acyclic graph does not.  \n",
    "\n",
    "![](../../../img/a_cyclical_graphs.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_3_'></a>[Directed](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directed Graphs**: Edges have a specific direction (A → B).  \n",
    "\n",
    "![](../../../img/directed-graph.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[Where else are DAGs used?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../img/airflow_dag.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAGs are widely used in streamlining data/ML operations that need to happen sequentially and at regular time intervals. Airflow is one of the most basic platforms where you can build this type of pipelines and monitor the success/failure of your pipelines. You can also schedule runs of pipelines, connect to cloud services, etc. Other schedulers used by data scientists are Prefect (recommended), Dask (for large-scale data processing), Kubeflow pipelines (can be overkill), DAGster. \n",
    "\n",
    "You'd do have to do some research before choosing any of these - Airflow is always a good starting point as it's open-source, but users complain that it's outdated compared to competitors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[Why Are DAGs Important for LLM Agents?](#toc0_)\n",
    "- **Task Execution Flow**: DAGs define clear steps in multi-agent workflows.\n",
    "- **Parallel Processing**: Independent tasks can run simultaneously.\n",
    "- **Dependency Management**: Ensures tasks execute in the correct order.\n",
    "\n",
    "LangGraph uses DAGs to structure multi-agent workflows, ensuring efficient and logical task progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_4_'></a>[Building our own DAG - a simple multi-agent system](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def query_understanding_node(state):\n",
    "    llm = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\")\n",
    "    response = llm.with_structured_output(QueryAnalysis).invoke([\n",
    "            {\"role\": \"system\", \"content\": red_cross_assistant_prompt},\n",
    "            {\"role\": \"user\", \"content\": state[\"response\"]},\n",
    "        ]\n",
    "    )\n",
    "    return {\"response\": response}\n",
    "\n",
    "def web_agent_node(state):\n",
    "    response = web_search(build_search_query(query=state['response']))\n",
    "    return {\"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "class ConversationBox(TypedDict):\n",
    "    \"\"\"State for the entire conversation graph\"\"\"\n",
    "    response: str\n",
    "\n",
    "workflow = StateGraph(ConversationBox)\n",
    "workflow.add_node(\"query_understanding\", query_understanding_node)\n",
    "workflow.add_node(\"web_agent\", web_agent_node)\n",
    "workflow.add_edge(START, \"query_understanding\")\n",
    "workflow.add_edge(\"query_understanding\", \"web_agent\")\n",
    "workflow.add_edge(\"web_agent\", END)\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SabinaFirtala\\anaconda3\\envs\\lizzy_nlp\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the LLM query search response:\n",
      "AIMessage(content='Find emergency shelter assistance near me.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 83, 'total_tokens': 91, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8aef92df-8419-41bc-8ae5-78fcc9f8666a-0', usage_metadata={'input_tokens': 83, 'output_tokens': 8, 'total_tokens': 91, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "{'response': 'snippet: Een brandwond of vergiftiging, bewusteloos raken of '\n",
      "             'iets kneuzen. Een ongeluk kan zomaar gebeuren. Met de gratis '\n",
      "             'EHBO-app van het Rode Kruis weet je altijd en overal wat je moet '\n",
      "             'doen., title: Altijd EHBO-hulp binnen handbereik met de Rode '\n",
      "             'Kruis-app, link: '\n",
      "             'https://www.rodekruis.nl/nieuwsbericht/altijd-ehbo-hulp-binnen-handbereik-met-de-rode-kruis-app/, '\n",
      "             'snippet: Je bent welkom. Heb je even geen geld om eten te kopen? '\n",
      "             'Geen zorgen. Dat kan iedereen overkomen. Wanneer kom ik in '\n",
      "             'aanmerking? Als je je aanmeldt, krijg je meteen boodschappen '\n",
      "             'mee. Dat doen we minimaal voor een maand. Ondertussen bespreken '\n",
      "             'en bekijken we de hele papierwinkel binnen drie maanden na je '\n",
      "             'aanmelding. We kijken […], title: Kom ik in aanmerking? - '\n",
      "             'Vereniging van Voedselbanken Nederland, link: '\n",
      "             'https://voedselbankennederland.nl/ik-zoek-hulp/kom-ik-in-aanmerking/, '\n",
      "             'snippet: Uit recent onderzoek van Ipsos I&O, in opdracht van het '\n",
      "             'Rode Kruis, blijkt dat 9% van de Nederlanders kampt met '\n",
      "             'voedselnood. Hoewel veel van deze mensen in aanmerking komen '\n",
      "             'voor voedselhulp, ontvangen ze deze niet altijd. Redenen '\n",
      "             'hiervoor kunnen zijn: onbekendheid met de beschikbare hulp of '\n",
      "             'schaamte om hulp te vragen. Zo werkt het dashboard […], title: '\n",
      "             'Samenwerking Kickstart AI en Voedselbanken Nederland tegen ..., '\n",
      "             'link: '\n",
      "             'https://voedselbankennederland.nl/samenwerking-kickstart-ai-en-voedselbanken-nederland-tegen-voedselarmoede/, '\n",
      "             'snippet: Blijf Groep helpt om huiselijk geweld te stoppen. Wij '\n",
      "             'bieden hulp aan alle betrokkenen: slachtoffers, kinderen en '\n",
      "             'plegers. Ons uitgangspunt is het geweld te stoppen en veiligheid '\n",
      "             'te creëren door hulp op maat., title: Blijf Groep - Blijf Groep, '\n",
      "             'link: https://www.blijfgroep.nl/'}\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"response\": \"Please help me!\"})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SabinaFirtala\\anaconda3\\envs\\lizzy_nlp\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the LLM query search response:\n",
      "AIMessage(content='Find food assistance near me.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 74, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f249b124-67a4-4ca4-b220-adfdcc5c1a28-0', usage_metadata={'input_tokens': 74, 'output_tokens': 7, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "{'response': 'snippet: Je bent welkom. Heb je even geen geld om eten te kopen? '\n",
      "             'Geen zorgen. Dat kan iedereen overkomen. Wanneer kom ik in '\n",
      "             'aanmerking? Als je je aanmeldt, krijg je meteen boodschappen '\n",
      "             'mee. Dat doen we minimaal voor een maand. Ondertussen bespreken '\n",
      "             'en bekijken we de hele papierwinkel binnen drie maanden na je '\n",
      "             'aanmelding. We kijken […], title: Kom ik in aanmerking? - '\n",
      "             'Vereniging van Voedselbanken Nederland, link: '\n",
      "             'https://voedselbankennederland.nl/ik-zoek-hulp/kom-ik-in-aanmerking/, '\n",
      "             'snippet: Jij kunt dan ook een enorme bijdrage leveren aan het '\n",
      "             'helpen van meer mensen. Zoals in het eerste artikel van deze '\n",
      "             'Vitamine te lezen, heb je daarmee niet alleen impact op een '\n",
      "             'gezin maar op de hele samenleving. Bovendien is het een enorme '\n",
      "             'stimulans voor onze 14.000 vrijwilligers. Het werk dat ze doen '\n",
      "             'is letterlijk […], title: Voor € 25,- help je een gezin een hele '\n",
      "             'maand - Vereniging van ..., link: '\n",
      "             'https://voedselbankennederland.nl/voor-e25-per-maand-help-je-een-gezin-aan-een-voedselpakket/, '\n",
      "             'snippet: In 2023 ontvingen Voedselbanken Nederland en de 177 '\n",
      "             'aangesloten voedselbanken ruim 25 miljoen euro aan donaties in '\n",
      "             'de vorm van voedsel en geld. Deze investering leidt volgens '\n",
      "             'Deloitte tot een maatschappelijke waarde van 297 miljoen euro. '\n",
      "             'Vorig jaar zijn in totaal ruim 180 duizend mensen geholpen. '\n",
      "             'Besparing kosten gezondheidszorg Deloitte signaleert in het '\n",
      "             'rapport dat […], title: Voedselbanken maken van elke euro twaalf '\n",
      "             'euro, link: '\n",
      "             'https://voedselbankennederland.nl/voedselbanken-maken-van-elke-euro-twaalf-euro/, '\n",
      "             'snippet: Tijdens de algemene ledenvergadering van de vereniging '\n",
      "             'van Nederlandse Voedselbanken op 30 november hebben de '\n",
      "             'Nederlandse Voedselbanken de waarden en normen rond de '\n",
      "             'toekenningscriteria per 1 januari 2025 vastgesteld., title: '\n",
      "             'Criteria Voedselbanken nog meer afgestemd op ambitie om meer '\n",
      "             'mensen te ..., link: '\n",
      "             'https://voedselbankennederland.nl/criteria-voedselbanken-nog-meer-afgestemd-op-ambitie-om-meer-mensen-te-helpen/'}\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"response\": \"I am hungry\"})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test out whether each individual node works, you can call them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SabinaFirtala\\anaconda3\\envs\\lizzy_nlp\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': QueryAnalysis(original_query='I am hungry', query_type='clear', domains=['Health & Wellbeing'], emotional_state='Neutral', language='English')}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_understanding_node({\"response\": \"I am hungry\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the LLM query search response:\n",
      "AIMessage(content='Find food assistance near me.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 74, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b2335398-6c21-4e7f-8be9-9e98ae89d265-0', usage_metadata={'input_tokens': 74, 'output_tokens': 7, 'total_tokens': 81, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': 'snippet: Je bent welkom. Heb je even geen geld om eten te kopen? Geen zorgen. Dat kan iedereen overkomen. Wanneer kom ik in aanmerking? Als je je aanmeldt, krijg je meteen boodschappen mee. Dat doen we minimaal voor een maand. Ondertussen bespreken en bekijken we de hele papierwinkel binnen drie maanden na je aanmelding. We kijken […], title: Kom ik in aanmerking? - Vereniging van Voedselbanken Nederland, link: https://voedselbankennederland.nl/ik-zoek-hulp/kom-ik-in-aanmerking/, snippet: Jij kunt dan ook een enorme bijdrage leveren aan het helpen van meer mensen. Zoals in het eerste artikel van deze Vitamine te lezen, heb je daarmee niet alleen impact op een gezin maar op de hele samenleving. Bovendien is het een enorme stimulans voor onze 14.000 vrijwilligers. Het werk dat ze doen is letterlijk […], title: Voor € 25,- help je een gezin een hele maand - Vereniging van ..., link: https://voedselbankennederland.nl/voor-e25-per-maand-help-je-een-gezin-aan-een-voedselpakket/, snippet: In 2023 ontvingen Voedselbanken Nederland en de 177 aangesloten voedselbanken ruim 25 miljoen euro aan donaties in de vorm van voedsel en geld. Deze investering leidt volgens Deloitte tot een maatschappelijke waarde van 297 miljoen euro. Vorig jaar zijn in totaal ruim 180 duizend mensen geholpen. Besparing kosten gezondheidszorg Deloitte signaleert in het rapport dat […], title: Voedselbanken maken van elke euro twaalf euro, link: https://voedselbankennederland.nl/voedselbanken-maken-van-elke-euro-twaalf-euro/, snippet: Tijdens de algemene ledenvergadering van de vereniging van Nederlandse Voedselbanken op 30 november hebben de Nederlandse Voedselbanken de waarden en normen rond de toekenningscriteria per 1 januari 2025 vastgesteld., title: Criteria Voedselbanken nog meer afgestemd op ambitie om meer mensen te ..., link: https://voedselbankennederland.nl/criteria-voedselbanken-nog-meer-afgestemd-op-ambitie-om-meer-mensen-te-helpen/'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_agent_node({\"response\": QueryAnalysis(original_query='I am hungry', query_type='clear', domains=['Health & Wellbeing'], emotional_state='Neutral', language='English')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's turn this into a more interesting graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emergency_node(state):\n",
    "    \"\"\"Returns emergency contact information\"\"\"\n",
    "    whatsapp_number = \"ADD RED CROSS WHATSAPP # HERE\"\n",
    "    return {\n",
    "        \"response\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f\"\"\"  \n",
    "                    This seems urgent and like you need immediate assistance. Please contact the Red Cross directly at this number {whatsapp_number}  \n",
    "                    to get help immediately.  \n",
    "                    For any medical emergency please contact 112.  \n",
    "                    \"\"\"\n",
    "            }\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_by_query_type(state):\n",
    "    \"\"\"\n",
    "    Routes to appropriate node based on query analysis\n",
    "    In query_understanding QueryAnalysis.query_type Literal[\"clear\", \"needs_clarification\", \"emergency\"]\n",
    "    \"\"\"\n",
    "    analysis = state[\"response\"]\n",
    "    # Route based on query type\n",
    "    if analysis.query_type == \"clear\":\n",
    "        return \"web_agent\"\n",
    "    elif analysis.query_type == \"emergency\":\n",
    "        return \"emergency\"\n",
    "        \n",
    "workflow = StateGraph(ConversationBox)\n",
    "workflow.add_node(\"query_understanding\", query_understanding_node)\n",
    "workflow.add_node(\"emergency\", emergency_node)\n",
    "workflow.add_node(\"web_agent\", web_agent_node)\n",
    "workflow.add_edge(START, \"query_understanding\")\n",
    "workflow.add_conditional_edges(\n",
    "        \"query_understanding\",\n",
    "        route_by_query_type,\n",
    "        {\n",
    "            \"web_agent\": \"web_agent\",\n",
    "            \"emergency\": \"emergency\",\n",
    "        }\n",
    "    )\n",
    "workflow.add_edge(\"emergency\", END)\n",
    "workflow.add_edge(\"web_agent\", END)\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SabinaFirtala\\anaconda3\\envs\\lizzy_nlp\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the LLM query search response:\n",
      "AIMessage(content='Healthy snack options for hunger mood upsurgence.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 74, 'total_tokens': 84, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4f3dd918-7f9e-4308-b606-72422af8f3a8-0', usage_metadata={'input_tokens': 74, 'output_tokens': 10, 'total_tokens': 84, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'response': \"snippet: Je bent welkom. Heb je even geen geld om eten te kopen? Geen zorgen. Dat kan iedereen overkomen. Wanneer kom ik in aanmerking? Als je je aanmeldt, krijg je meteen boodschappen mee. Dat doen we minimaal voor een maand. Ondertussen bespreken en bekijken we de hele papierwinkel binnen drie maanden na je aanmelding. We kijken […], title: Kom ik in aanmerking? - Vereniging van Voedselbanken Nederland, link: https://voedselbankennederland.nl/ik-zoek-hulp/kom-ik-in-aanmerking/, snippet: Jij kunt dan ook een enorme bijdrage leveren aan het helpen van meer mensen. Zoals in het eerste artikel van deze Vitamine te lezen, heb je daarmee niet alleen impact op een gezin maar op de hele samenleving. Bovendien is het een enorme stimulans voor onze 14.000 vrijwilligers. Het werk dat ze doen is letterlijk […], title: Voor € 25,- help je een gezin een hele maand - Vereniging van ..., link: https://voedselbankennederland.nl/voor-e25-per-maand-help-je-een-gezin-aan-een-voedselpakket/, snippet: Henk Staghouwer past bescheidenheid. Hij zit nog in de 'verwonderingsfase', zegt hij zelf. Dat neemt niet weg dat het bestuur van Voedselbanken Nederland al een brief geschreven heeft aan de informateur om het armoedeprobleem nog eens extra op de politieke agenda te zetten. De boodschap is simpel. Zorg dat er een minister van armoede komt, vereenvoudig de regelgeving en geef mensen ..., title: Niemand mag honger hebben - Vereniging van Voedselbanken Nederland, link: https://voedselbankennederland.nl/niemand-mag-honger-hebben/, snippet: In 2023 ontvingen Voedselbanken Nederland en de 177 aangesloten voedselbanken ruim 25 miljoen euro aan donaties in de vorm van voedsel en geld. Deze investering leidt volgens Deloitte tot een maatschappelijke waarde van 297 miljoen euro. Vorig jaar zijn in totaal ruim 180 duizend mensen geholpen. Besparing kosten gezondheidszorg Deloitte signaleert in het rapport dat […], title: Voedselbanken maken van elke euro twaalf euro, link: https://voedselbankennederland.nl/voedselbanken-maken-van-elke-euro-twaalf-euro/\"}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"response\": \"I am hungry\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SabinaFirtala\\anaconda3\\envs\\lizzy_nlp\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': '  \\n'\n",
      "             '                    This seems urgent and like you need '\n",
      "             'immediate assistance. Please contact the Red Cross directly at '\n",
      "             'this number ADD RED CROSS WHATSAPP # HERE  \\n'\n",
      "             '                    to get help immediately.  \\n'\n",
      "             '                    For any medical emergency please contact '\n",
      "             '112.  \\n'\n",
      "             '                    ',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"response\": \"Please help me!\"})\n",
    "pprint(response['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Conclusion](#toc0_)\n",
    "- **LLM agents** enable intelligent text-based automation.\n",
    "- **LangChain** enhances LLMs with tools, memory, and structured pipelines.\n",
    "- **LangGraph** facilitates multi-agent workflows for complex AI interactions.\n",
    "\n",
    "With these tools, you can build powerful AI-driven applications. 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Extra](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Tool-Using Agent](#toc0_)\n",
    "An agent that integrates with APIs or tools (e.g., calculator, weather API, web scraper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool # When we use the scraping tool, the output will be compatible with LangChain\n",
    "def web_scrape_tool(url):\n",
    "    \"\"\"Sends simple request to websites and retrieves the answer\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        content = BeautifulSoup(response.text, 'html.parser')\n",
    "        content_list = [p.text.replace('\\n', '') for p in content.find_all('p')]\n",
    "        final_content = \"\\n\".join(content_list)\n",
    "        return final_content[:1000]  # Limit to first 1000 characters\n",
    "    except Exception as e:\n",
    "        return f\"Error scraping {url}: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "example_url = \"https://en.wikipedia.org/wiki/LangChain\"\n",
    "message_history = [\n",
    "    AIMessage(\"You are a web research assistant who can scrape and summarize web content.\"),\n",
    "    HumanMessage(f\"Can you summarize the info on this webpage: {example_url}?\"),\n",
    "]\n",
    "llm = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\", temperature=0).bind_tools([web_scrape_tool])\n",
    "response = llm.invoke(message_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    if tool_call['name'].lower() == 'web_scrape_tool':\n",
    "        url = tool_call['args']['url']\n",
    "        tool_output = web_scrape_tool(url)\n",
    "        tool_message = ToolMessage(\n",
    "            content=tool_output, \n",
    "            tool_call_id=tool_call['id']\n",
    "        )\n",
    "        message_history.append(response)\n",
    "        message_history.append(tool_message)\n",
    "\n",
    "message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(message_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we didn't get an answer to our query. Instead, we were able to extract the URL from the user's prompt. To also get the result, we need to pass the tool input as a message!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[RAG Agent](#toc0_)\n",
    "\n",
    "RAG Agents require a bit more in-depth view over vector databases and embeddings but you can find a tutorial [here](https://www.kdnuggets.com/implement-agentic-rag-using-langchain-part-2)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lizzy_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
