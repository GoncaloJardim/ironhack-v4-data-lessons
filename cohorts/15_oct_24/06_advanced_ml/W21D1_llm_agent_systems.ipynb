{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Building LLM Agents - Red Cross Helpful Information as Aid](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Building LLM Agents - Red Cross Helpful Information as Aid](#toc1_)    \n",
    "  - [Introduction to LLM Agents](#toc1_1_)    \n",
    "    - [What Are LLM Agents?](#toc1_1_1_)    \n",
    "    - [How Do LLM Agents Work?](#toc1_1_2_)    \n",
    "  - [Building a Basic LLM Agent with OpenAI](#toc1_2_)    \n",
    "    - [Prompt Engineering](#toc1_2_1_)    \n",
    "    - [Structured Output](#toc1_2_2_)    \n",
    "  - [Enhancing LLM Agents with LangChain](#toc1_3_)    \n",
    "    - [Simple Agent](#toc1_3_1_)    \n",
    "    - [Web Search Agent](#toc1_3_2_)    \n",
    "  - [Multi-Agent Systems with LangGraph](#toc1_4_)    \n",
    "    - [What's a DAG?](#toc1_4_1_)    \n",
    "      - [Graph](#toc1_4_1_1_)    \n",
    "      - [Acyclic](#toc1_4_1_2_)    \n",
    "      - [Directed](#toc1_4_1_3_)    \n",
    "    - [Where else are DAGs used?](#toc1_4_2_)    \n",
    "    - [Why Are DAGs Important for LLM Agents?](#toc1_4_3_)    \n",
    "    - [Building our own DAG - a simple multi-agent system](#toc1_4_4_)    \n",
    "  - [Putting it all together](#toc1_5_)    \n",
    "  - [Conclusion](#toc1_6_)    \n",
    "- [Extra](#toc2_)    \n",
    "  - [Tool-Using Agent](#toc2_1_)    \n",
    "  - [RAG Agent](#toc2_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Introduction to LLM Agents](#toc0_)\n",
    "\n",
    "### <a id='toc1_1_1_'></a>[What Are LLM Agents?](#toc0_)\n",
    "> Agents are systems that use LLMs as **reasoning engines** to determine which actions to take and the inputs necessary to perform the action. After executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. This is often achieved via tool-calling. *(Source: [LangChain](https://python.langchain.com/docs/tutorials/agents/))*\n",
    "\n",
    "### <a id='toc1_1_2_'></a>[How Do LLM Agents Work?](#toc0_)\n",
    "Just like any other LLM. The only difference is that based on the constraints we put on LLM agents (e.g. prompt, structured output), we are able to get them to fulfill a specific role without further model finetuning. An LLM agent typically sits within a pipeline of LLM agents, like we see in [this example](https://langchain-mrkl.streamlit.app/?ref=streamlit-io-gallery-llms). \n",
    "\n",
    "## <a id='toc1_2_'></a>[Building a Basic LLM Agent with OpenAI](#toc0_)\n",
    "Ensure you have the OpenAI Python library installed and use a `.env` file to set up your API key (`OPENAI_API_KEY`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up your API key and define a simple LLM agent function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history_1 = [{\"role\": \"system\", \"content\": \"You are a helpful assistant\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os \n",
    "\n",
    "def llm_agent(input_, message_history, model=\"gpt-3.5-turbo\"):\n",
    "    llm = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    message_history.append({\"role\": \"user\", \"content\": f\"{input_}\"})\n",
    "\n",
    "    # Generate a response from the chatbot model\n",
    "    completion = llm.chat.completions.create(\n",
    "      model=model,\n",
    "      messages=message_history\n",
    "    )\n",
    "\n",
    "    # We save the assistant response\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "    return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent(\"I am hungry\", message_history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is not inherently a bad reply, it doesn't provide any specific support right away. So during this lesson, we'll try to make this better, bit by bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Prompt Engineering](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_list = [\n",
    "    \"Shelter\",\n",
    "    \"Health & Wellbeing\",\n",
    "    \"Safety & Protection\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_cross_assistant_prompt = \"\"\"You are an expert query analyzer for a Red Cross virtual assistant.\n",
    "    Analyze the query to understand the user's needs, emotional state, and language.\n",
    "    Pay special attention to any signs of emergency or urgent needs.\n",
    "\n",
    "    If you detect any of these, mark as EMERGENCY:\n",
    "    - Immediate danger\n",
    "    - Medical emergencies \n",
    "    - Severe distress\n",
    "    - Threats to basic safety\n",
    "\n",
    "    If the query is unclear, you should return relevant domains from this list as clarification options:\n",
    "    {}\n",
    "\n",
    "    Important: You will analyze:\n",
    "    1. Query clarity and type (clear/needs_clarification/emergency)\n",
    "    2. Domains of need, from this list of options {} or \"Other\"\n",
    "    3. Emotional state from language and content\n",
    "    4. Language of query\n",
    "    \"\"\".format(domain_list, domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history_2 = [{\"role\": \"system\", \"content\": red_cross_assistant_prompt}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent(\"I am hungry\", message_history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the issue with this is that it doesn't provide any useful information, it just asks clarifying questions. But that's ok, we can create an LLM with..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[Structured Output](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from typing_extensions import Union\n",
    "from pydantic import BaseModel # pydantic is a data validation library widely used in the industry\n",
    "\n",
    "Domains = Literal[\n",
    "    \"Shelter\",\n",
    "    \"Health & Wellbeing\",\n",
    "    \"Safety & Protection\",\n",
    "]\n",
    "DomainWithOther = Union[Domains, Literal[\"Other\"]]\n",
    "\n",
    "class QueryAnalysis(BaseModel):\n",
    "    \"\"\"Analysis output from Query Understanding Agent\"\"\"\n",
    "    query_type: Literal[\"clear\", \"needs_clarification\", \"emergency\"]\n",
    "    domains: List[DomainWithOther]\n",
    "    emotional_state: str\n",
    "    language: str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_agent(input_, message_history, model=\"gpt-4o-2024-08-06\"):\n",
    "    llm = openai.OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    message_history.append({\"role\": \"user\", \"content\": f\"{input_}\"})\n",
    "\n",
    "    # Generate a response from the chatbot model\n",
    "    completion = llm.beta.chat.completions.parse(\n",
    "      model=model,\n",
    "      messages=message_history,\n",
    "      response_format=QueryAnalysis\n",
    "    )\n",
    "\n",
    "    # We save the assistant response\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "    return message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_agent(\"I am hungry\", message_history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! We've already created a useful AI agent. However, if we wanted to switch to a different provider, e.g. Anthropic, or use an open-source LLM, e.g. Llama, DeepSeek, we would need to change our code completely! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Enhancing LLM Agents with LangChain](#toc0_)\n",
    "\n",
    "With LangChain, we can use a lot more models without changing our code each time we change an LLM. Additionally, LangChain is able to couple multiple agents together, allowing an LLM to answer more complex queries more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain_community\n",
    "# !pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Simple Agent](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\")\n",
    "response = llm.invoke(message_history_1)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(message_history_2)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.with_structured_output(QueryAnalysis).invoke(message_history_2)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I was able to do the exact same thing with significantly fewer lines of code! Now let's see what other agents we can play with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Web Search Agent](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "domain_sites = {\n",
    "        \"food\": [\"voedselbank.nl\", \"voedselbankennederland.nl\"],\n",
    "        \"shelter\": [\"deregenboog.org\", \"opvang.nl\"],\n",
    "        \"healthcare\": [\"ggd.nl\", \"zorgverzekeringslijn.nl\"],\n",
    "        \"domestic_violence\": [\"veiligthuis.nl\", \"blijfgroep.nl\"],\n",
    "    }\n",
    "\n",
    "def web_search(query: str) -> dict:\n",
    "    wrapper = DuckDuckGoSearchAPIWrapper(region=\"nl-nl\", max_results=2) # time='y' limit to past year (m, d, w)\n",
    "    search_tool = DuckDuckGoSearchResults(api_wrapper=wrapper)\n",
    "    return search_tool.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snippet: The expression \"Ik heb honger\" is a common and neutral way to say \"I\\'m hungry\" in both formal and casual contexts. There are no specific expressions that make the translation formal or casual in this context., title: How do you say \"i\\'m hungry \" in Dutch? | HiNative, link: https://hinative.com/questions/26523530, snippet: Explore the reasons why you might still feel hungry after eating and discover actionable tips to promote fullness and manage hunger effectively., title: Stomach Feel Empty After Eating? 6 Possible Reasons Why | Season, link: https://www.seasonhealth.com/blog/why-does-my-stomach-feel-empty-after-eating, snippet: Waking up hungry is more than just a cue that you\\'re ready for breakfast. Three experts on the reasons you\\'re waking up hungry and what it says about your health., title: 8 Reasons You May Be Waking Up Hungry, According to Experts - TODAY, link: https://www.today.com/health/health/waking-up-hungry-rcna192814, snippet: Feeling hungry but lacking appetite can be frustrating. Learn the causes, from medical conditions to mental health, and discover tips to regain your desire to eat. For New Providers, title: Hungry, but No Appetite: Why it Happens & What to Do | Season, link: https://www.seasonhealth.com/blog/why-do-you-feel-hungry-but-dont-want-to-eat'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search(\"I am hungry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can search stuff on the internet now. Let's see how we can combine this with our previous agent to get a better search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_web_search(query: str, domains: list = None, location: str = \"Netherlands\", domain_sites=domain_sites) -> dict:\n",
    "    \"\"\"\n",
    "    Perform a targeted web search with domain-specific site prioritization.\n",
    "    \"\"\"\n",
    "    # Initialize LLM\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-3-5-haiku-20241022\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Prepare relevant sites\n",
    "    relevant_sites = [\"rodekruis.nl\"]\n",
    "    if domains:\n",
    "        for domain in domains:\n",
    "            if domain.lower() in domain_sites:\n",
    "                relevant_sites.extend(domain_sites[domain.lower()])\n",
    "\n",
    "    # Prepare search query\n",
    "    system_prompt = \"\"\"\n",
    "    Create a simple search query (maximum 10 words) in English or Dutch \n",
    "    that will help find relevant assistance information.\n",
    "    Return ONLY the search query, no explanation or strategy.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate search query using LLM\n",
    "    search_query_response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Original query: {query}\n",
    "            Location: {location}\n",
    "            Domains: {domains or 'Not specified'}\n",
    "        \"\"\"}\n",
    "    ])\n",
    "\n",
    "    # Prepare search query with domain priority\n",
    "    search_query = search_query_response.content\n",
    "    domain_priority = \" OR \".join(f\"site:{site}\" for site in relevant_sites)\n",
    "    full_query = f\"{search_query} {domain_priority}\"\n",
    "\n",
    "    # Perform web search\n",
    "    wrapper = DuckDuckGoSearchAPIWrapper(region=\"nl-nl\", max_results=2)\n",
    "    search_tool = DuckDuckGoSearchResults(api_wrapper=wrapper)\n",
    "    search_results = search_tool.run(full_query)\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"search_query\": full_query,\n",
    "        \"results\": search_results,\n",
    "        \"domains\": domains,\n",
    "        \"location\": location\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    Create a simple search query (maximum 10 words) in English or Dutch that will find help information.\n",
    "    Return ONLY the search query, no explanation or strategy.\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "\n",
    "    # Build final search query\n",
    "    search_query = response.content\n",
    "    print(search_query)\n",
    "    domain_priority = \" OR \".join(f\"site:{site}\" for site in relevant_sites)\n",
    "    full_query = f\"{search_query} {domain_priority}\"\n",
    "\n",
    "    # Perform search\n",
    "    results = web_search(full_query)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Multi-Agent Systems with LangGraph](#toc0_)\n",
    "Although we can already build a multi-agent system with LangChain, we have one constraint: the sequence of actions can only be linear. LangGraph extends LangChain by enabling parallel/conditional interactions through DAGs (Directed Acyclic Graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[What's a DAG?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **Directed Acyclic Graph (DAG)** is a graph structure where nodes are connected by directed edges, and there are no cycles. This means that information flows in one direction without looping back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_1_'></a>[Graph](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **graph** is a data structure consisting of nodes (or vertices) connected by edges. Graphs are widely used in computer science, mathematics, and AI to model relationships between entities.\n",
    "\n",
    "![](../../../img/graph_edge_matrix.png)  \n",
    "(Source: [HuggingFace](http://huggingface.co/blog/intro-graphml))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_2_'></a>[Acyclic](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Cyclic vs. Acyclic Graphs**: A cyclic graph has cycles, whereas an acyclic graph does not.  \n",
    "\n",
    "![](../../../img/a_cyclical_graphs.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_3_'></a>[Directed](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directed Graphs**: Edges have a specific direction (A â†’ B).  \n",
    "\n",
    "![](../../../img/directed-graph.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[Where else are DAGs used?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../../../img/airflow_dag.png)  \n",
    "(Source: [Astronomer](https://www.astronomer.io/docs/learn/dags/))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAGs are widely used in streamlining data/ML operations that need to happen sequentially and at regular time intervals. Airflow is one of the most basic platforms where you can build this type of pipelines and monitor the success/failure of your pipelines. You can also schedule runs of pipelines, connect to cloud services, etc. Other schedulers used by data scientists are Prefect (recommended), Dask (for large-scale data processing), Kubeflow pipelines (can be overkill), DAGster. \n",
    "\n",
    "You'd do have to do some research before choosing any of these - Airflow is always a good starting point as it's open-source, but users complain that it's outdated compared to competitors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[Why Are DAGs Important for LLM Agents?](#toc0_)\n",
    "- **Task Execution Flow**: DAGs define clear steps in multi-agent workflows.\n",
    "- **Parallel Processing**: Independent tasks can run simultaneously.\n",
    "- **Dependency Management**: Ensures tasks execute in the correct order.\n",
    "\n",
    "LangGraph uses DAGs to structure multi-agent workflows, ensuring efficient and logical task progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_4_'></a>[Building our own DAG - a simple multi-agent system](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import Message\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "            Original query: {query_context['original_query']}\n",
    "            Location: {query_context['entities'].get('location', 'Netherlands')}\n",
    "            Domains: {query_context['domains']}\n",
    "            Language: {query_context['language']}\n",
    "        \"\"\"}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Putting it all together](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import Message\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def query_understanding(state):\n",
    "    response = ChatOpenAI().predict(\"Provide an initial analysis on AI safety.\")\n",
    "    return Message(response)\n",
    "\n",
    "def web_search(state):\n",
    "    response = ChatOpenAI().predict(f\"Expand on the following: {state['message']}\")\n",
    "    return Message(response)\n",
    "\n",
    "def emergency_node(state):\n",
    "    \"\"\"Returns emergency contact information\"\"\"\n",
    "    whatsapp_number = \"ADD RED CROSS WHATSAPP # HERE\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f\"\"\"  \n",
    "                    This seems urgent and like you need immediate assistance. Please contact the Red Cross directly at this number {whatsapp_number}  \n",
    "                    to get help immediately.  \n",
    "                    For any medical emergency please contact 112.  \n",
    "                    \"\"\"\n",
    "            }\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "def route_by_query_type(state):\n",
    "    \"\"\"\n",
    "    Routes to appropriate node based on query analysis\n",
    "    In query_understanding QueryAnalysis.query_type Literal[\"clear\", \"needs_clarification\", \"emergency\"]\n",
    "    \"\"\"\n",
    "    analysis = state[\"analysis\"]\n",
    "    # Route based on query type\n",
    "    if analysis[\"query_type\"] == \"clear\":\n",
    "        return \"web_agent\"\n",
    "    elif analysis[\"query_type\"] == \"emergency\":\n",
    "        return \"emergency\"\n",
    "        \n",
    "workflow = StateGraph()\n",
    "workflow.add_node(\"await_clarification\", await_clarification_node)\n",
    "workflow.add_node(\"emergency\", emergency_node)\n",
    "workflow.add_node(\"web_agent\", web_agent_node)\n",
    "workflow.add_edge(START, \"query_understanding\")\n",
    "workflow.add_conditional_edges(\n",
    "        \"query_understanding\",\n",
    "        route_by_query_type,\n",
    "        {\n",
    "            \"web_agent\": \"web_agent\",\n",
    "            \"emergency\": \"emergency\",\n",
    "        }\n",
    "    )\n",
    "workflow.add_edge(\"emergency\", END)\n",
    "workflow.add_edge(\"web_agent\", END)\n",
    "workflow.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Conclusion](#toc0_)\n",
    "- **LLM agents** enable intelligent text-based automation.\n",
    "- **LangChain** enhances LLMs with tools, memory, and structured pipelines.\n",
    "- **LangGraph** facilitates multi-agent workflows for complex AI interactions.\n",
    "\n",
    "With these tools, you can build powerful AI-driven applications. ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Extra](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Tool-Using Agent](#toc0_)\n",
    "An agent that integrates with APIs or tools (e.g., calculator, weather API, web scraper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool # When we use the scraping tool, the output will be compatible with LangChain\n",
    "def web_scrape_tool(url):\n",
    "    \"\"\"Sends simple request to websites and retrieves the answer\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        content = BeautifulSoup(response.text, 'html.parser')\n",
    "        content_list = [p.text.replace('\\n', '') for p in content.find_all('p')]\n",
    "        final_content = \"\\n\".join(content_list)\n",
    "        return final_content[:1000]  # Limit to first 1000 characters\n",
    "    except Exception as e:\n",
    "        return f\"Error scraping {url}: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "example_url = \"https://en.wikipedia.org/wiki/LangChain\"\n",
    "message_history = [\n",
    "    AIMessage(\"You are a web research assistant who can scrape and summarize web content.\"),\n",
    "    HumanMessage(f\"Can you summarize the info on this webpage: {example_url}?\"),\n",
    "]\n",
    "llm = init_chat_model(\"gpt-3.5-turbo\", model_provider=\"openai\", temperature=0).bind_tools([web_scrape_tool])\n",
    "response = llm.invoke(message_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tool_call in response.tool_calls:\n",
    "    if tool_call['name'].lower() == 'web_scrape_tool':\n",
    "        url = tool_call['args']['url']\n",
    "        tool_output = web_scrape_tool(url)\n",
    "        tool_message = ToolMessage(\n",
    "            content=tool_output, \n",
    "            tool_call_id=tool_call['id']\n",
    "        )\n",
    "        message_history.append(response)\n",
    "        message_history.append(tool_message)\n",
    "\n",
    "message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(message_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we didn't get an answer to our query. Instead, we were able to extract the URL from the user's prompt. To also get the result, we need to pass the tool input as a message!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[RAG Agent](#toc0_)\n",
    "\n",
    "RAG Agents require a bit more in-depth view over vector databases and embeddings but you can find a tutorial [here](https://www.kdnuggets.com/implement-agentic-rag-using-langchain-part-2)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lizzy_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
