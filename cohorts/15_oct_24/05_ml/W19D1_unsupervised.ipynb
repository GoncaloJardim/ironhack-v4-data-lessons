{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Unsupervised Learning](#toc1_)    \n",
    "  - [Load breast cancer data](#toc1_1_)    \n",
    "  - [Dimensionality reduction](#toc1_2_)    \n",
    "    - [PCA (Principal Component Analysis)](#toc1_2_1_)    \n",
    "    - [How to choose the number of principal components?](#toc1_2_2_)    \n",
    "  - [Clustering](#toc1_3_)    \n",
    "    - [Centroid-based clustering - K-Means](#toc1_3_1_)    \n",
    "      - [Elbow method - choosing the # of clusters](#toc1_3_1_1_)    \n",
    "    - [Agglomerative/Hierarchical/Connectivity-based clustering](#toc1_3_2_)    \n",
    "      - [Ward linkage](#toc1_3_2_1_)    \n",
    "      - [Complete linkage](#toc1_3_2_2_)    \n",
    "      - [Single linkage](#toc1_3_2_3_)    \n",
    "    - [Density-based clustering - DBSCAN](#toc1_3_3_)    \n",
    "  - [Clustering metrics](#toc1_4_)    \n",
    "- [Resources](#toc2_)    \n",
    "- [References](#toc3_)    \n",
    "- [Acknowledgements](#toc4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Unsupervised Learning](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mwD_ZUaGN9b5"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'simple_white'\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import cluster, datasets\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Load breast cancer data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 569\n",
      "\n",
      ":Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      ":Attribute Information:\n",
      "    - radius (mean of distances from center to points on the perimeter)\n",
      "    - texture (standard deviation of gray-scale values)\n",
      "    - perimeter\n",
      "    - area\n",
      "    - smoothness (local variation in radius lengths)\n",
      "    - compactness (perimeter^2 / area - 1.0)\n",
      "    - concavity (severity of concave portions of the contour)\n",
      "    - concave points (number of concave portions of the contour)\n",
      "    - symmetry\n",
      "    - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "    The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "    worst/largest values) of these features were computed for each image,\n",
      "    resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "    10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "    - class:\n",
      "            - WDBC-Malignant\n",
      "            - WDBC-Benign\n",
      "\n",
      ":Summary Statistics:\n",
      "\n",
      "===================================== ====== ======\n",
      "                                        Min    Max\n",
      "===================================== ====== ======\n",
      "radius (mean):                        6.981  28.11\n",
      "texture (mean):                       9.71   39.28\n",
      "perimeter (mean):                     43.79  188.5\n",
      "area (mean):                          143.5  2501.0\n",
      "smoothness (mean):                    0.053  0.163\n",
      "compactness (mean):                   0.019  0.345\n",
      "concavity (mean):                     0.0    0.427\n",
      "concave points (mean):                0.0    0.201\n",
      "symmetry (mean):                      0.106  0.304\n",
      "fractal dimension (mean):             0.05   0.097\n",
      "radius (standard error):              0.112  2.873\n",
      "texture (standard error):             0.36   4.885\n",
      "perimeter (standard error):           0.757  21.98\n",
      "area (standard error):                6.802  542.2\n",
      "smoothness (standard error):          0.002  0.031\n",
      "compactness (standard error):         0.002  0.135\n",
      "concavity (standard error):           0.0    0.396\n",
      "concave points (standard error):      0.0    0.053\n",
      "symmetry (standard error):            0.008  0.079\n",
      "fractal dimension (standard error):   0.001  0.03\n",
      "radius (worst):                       7.93   36.04\n",
      "texture (worst):                      12.02  49.54\n",
      "perimeter (worst):                    50.41  251.2\n",
      "area (worst):                         185.2  4254.0\n",
      "smoothness (worst):                   0.071  0.223\n",
      "compactness (worst):                  0.027  1.058\n",
      "concavity (worst):                    0.0    1.252\n",
      "concave points (worst):               0.0    0.291\n",
      "symmetry (worst):                     0.156  0.664\n",
      "fractal dimension (worst):            0.055  0.208\n",
      "===================================== ====== ======\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      ":Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      ":Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      ":Donor: Nick Street\n",
      "\n",
      ":Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      "|details-start|\n",
      "**References**\n",
      "|details-split|\n",
      "\n",
      "- W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\n",
      "  for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\n",
      "  Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "  San Jose, CA, 1993.\n",
      "- O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\n",
      "  prognosis via linear programming. Operations Research, 43(4), pages 570-577,\n",
      "  July-August 1995.\n",
      "- W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "  to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\n",
      "  163-171.\n",
      "\n",
      "|details-end|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unsupervised Learning Class\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = cancer['data']\n",
    "y = cancer['target']\n",
    "display(X.shape)\n",
    "display(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  label  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's visualize all the data in a dataframe\n",
    "data = pd.DataFrame(X, columns=cancer['feature_names'])\n",
    "data['label'] = y\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Dimensionality reduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[PCA (Principal Component Analysis)](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a statistical technique used for dimensionality reduction. It transforms the data into a new coordinate system such that the greatest variance by any projection of the data comes to lie on the first coordinate (called the first principal component), the second greatest variance on the second coordinate, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://imgs.search.brave.com/1u8pddu4FRUlSAuxj0i992lYN__bYby0JDUEqF2abEM/rs:fit:860:0:0/g:ce/aHR0cHM6Ly9icmFk/bGV5Ym9laG1rZS5n/aXRodWIuaW8vSE9N/TC8xNS1wY2FfZmls/ZXMvZmlndXJlLWh0/bWwvY3JlYXRlLXBj/YS1pbWFnZS0xLnBu/Zw)  \n",
    "(Source: [Hands-on Machine Learning with R, Bradley Boehmke](https://bradleyboehmke.github.io/HOML/pca.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, we're not looking to predict whether or not a patient has a malignant/benign tumour, but if we can create 2 clusters corresponding to the most similar tumours. However, we think that the malignant tumours are significantly different from benign tumours, which is why we're looking to see if we can separate clusters based on the tumour type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check differences between features and labels\n",
    "plot_options, charts = plt.subplots(5, 6, figsize=(20, 7))\n",
    "malignant = data[data['label'] == 1]\n",
    "benign = data[data['label'] == 0]\n",
    "#ravel flattens the array so we don't need 2 indexes\n",
    "charts_1d = charts.ravel()\n",
    "for i in range(30):\n",
    "  charts_1d[i].hist(malignant.iloc[:, i], bins=50, alpha=.5)\n",
    "  charts_1d[i].hist(benign.iloc[:, i], bins=50, alpha=.5)\n",
    "  charts_1d[i].set_title(data.columns[i])\n",
    "  plot_options.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we'd want to see if we can cluster the tumours based on multiple features (like we did for the iris dataset some time ago) but in this case we have >30 labels, which makes a pairplot take ages to run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data, hue = 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still look to see if we can separate clusters based on 2 features at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster boundary for features 1, 29\n",
    "fig = px.scatter(x=data.iloc[:, 1], y=data.iloc[:, 29], color=y, opacity=0.5)\n",
    "fig.update_layout(xaxis_title=data.columns[1], yaxis_title=data.columns[29], height=600, width=600)\n",
    "fig.show()\n",
    "\n",
    "# Cluster boundary for features 28, 29\n",
    "fig = px.scatter(x=data.iloc[:, 28], y=data.iloc[:, 29], color=y, opacity=0.5)\n",
    "fig.update_layout(xaxis_title=data.columns[28], yaxis_title=data.columns[29], height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(cancer['data'])\n",
    "\n",
    "X_scaled = scaler.transform(cancer['data'])\n",
    "pd.DataFrame(X_scaled, columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need to perform scaling before running the PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the PCA object\n",
    "# the number of components chosen will be the new number of features!\n",
    "pca = PCA(n_components=3)\n",
    "# fit the PCA model to breast cancer data\n",
    "pca.fit(X_scaled)\n",
    "# it's like we have three new axis (those defined by the PCA principal components)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "pd.DataFrame(X_pca, columns=['PCA_1', 'PCA_2', 'PCA_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.shape)\n",
    "display(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=X_pca[:, 0], y=X_pca[:, 1], color=y, opacity=0.5)\n",
    "fig.update_layout(xaxis_title='1st principal component', yaxis_title='2nd principal component', height=600, width=600)\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(x=X_pca[:, 1], y=X_pca[:, 2], color=y, opacity=0.5)\n",
    "fig.update_layout(xaxis_title='2nd principal component', yaxis_title='3rd principal component', height=600, width=600)\n",
    "fig.show()\n",
    "\n",
    "fig = px.scatter(x=X_pca[:, 0], y=X_pca[:, 2], color=y, opacity=0.5)\n",
    "fig.update_layout(xaxis_title='1st principal component', yaxis_title='3rd principal component', height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[How to choose the number of principal components?](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each PCA feature has a little bit of each original feture\n",
    "# The PCA tells you how much of the original features each new feature contains\n",
    "pd.DataFrame(pca.components_, columns=cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Matplotlib\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mmatshow(pca\u001b[38;5;241m.\u001b[39mcomponents_, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviridis\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39myticks([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst component\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSecond component\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThird component\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mcolorbar()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Matplotlib\n",
    "plt.matshow(pca.components_, cmap='viridis')\n",
    "plt.yticks([0, 1, 2], [\"First component\", \"Second component\",\"Third component\"])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(data.columns)), data.columns, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Mathematically, the new features (principal components) are a LINEAR COMBINATION of the previous (old) features and the weights of each of them are represented in the diagram above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Clustering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Centroid-based clustering - K-Means](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn.sanity.io/images/kuana2sp/production/4a7a2b92082d482c56e0c6396064ca23074168ac-1020x752.png?w=1080&fit=max&auto=format)  \n",
    "(Source: [Getting started with k-means clustering in Python, Dr J Rogel-Salazar](https://domino.ai/blog/getting-started-with-k-means-clustering-in-python))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "p6nIROyG6n9L",
    "outputId": "0728c9a8-2684-404f-941e-824232c867a5"
   },
   "outputs": [],
   "source": [
    "# Creating 3 clusters artificially to illustrate the algorithm\n",
    "n_samples = 1500\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, centers=3, cluster_std=0.7, n_features=2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review initial data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run clustering with:\n",
    "\n",
    "a) k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "K9Dq6mveD5NA",
    "outputId": "cf438724-f850-480e-8ff7-184faadcaf22"
   },
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "pred = kmeans.predict(X)\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_laoyout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "StVvxxOhDghk",
    "outputId": "dbcbe303-68fc-484a-fcc1-3e48a19e0926"
   },
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "pred = kmeans.predict(X)\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "1s6LnkHE6n_9",
    "outputId": "5beb7a03-e208-458f-91e5-78eecf507d8f"
   },
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "pred = kmeans.predict(X)\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_1_1_'></a>[Elbow method - choosing the # of clusters](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()\n",
    "# even though data was generated with 12 centers, 5 clusters could make sense, even 7 or 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select a number of clusters using the elbow heuristic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cluster.KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(2,20))\n",
    "visualizer.fit(X)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, any k between 4 and 8 would be good enough for this problem. Remember, we're not looking to minimize the error in this case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cluster.KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(1495,1499))\n",
    "visualizer.fit(X)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to minimize the error, we end up with an unusable number of clusters, which defeats the purpose of running the algorithm to begin with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_2_'></a>[Agglomerative/Hierarchical/Connectivity-based clustering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.geeksforgeeks.org/wp-content/uploads/20200204181551/Untitled-Diagram71.png)  \n",
    "(Source: [Hierarchical Clustering in Machine Learning, Geeks 4 Geeks](https://www.geeksforgeeks.org/ml-hierarchical-clustering-agglomerative-and-divisive-clustering/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gw_p6wjj6oC-"
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_1_'></a>[Ward linkage](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "d0MkbX9PRHKj",
    "outputId": "f7f0aeaa-8d95-472a-92a9-77a219c27779"
   },
   "outputs": [],
   "source": [
    "# ward linkage tends to produce relatively equally sized clusters\n",
    "agglomerative = cluster.AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
    "pred = agglomerative.fit_predict(X)\n",
    "\n",
    "# Matplotlib\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=pred, alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "# Plotly\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_2_'></a>[Complete linkage](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "QznfD0ONRmC6",
    "outputId": "5189539b-ec7d-4f42-e059-4a45ad94be1c"
   },
   "outputs": [],
   "source": [
    "# complete linkage penalizes heavily outliers\n",
    "agglomerative = cluster.AgglomerativeClustering(n_clusters=3,linkage='complete')\n",
    "pred = agglomerative.fit_predict(X)\n",
    "\n",
    "# Matplotlib\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.scatter(X[:, 0], X[:, 1], c=pred,alpha=0.5)\n",
    "# plt.show()\n",
    "\n",
    "# Plotly\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_3_2_3_'></a>[Single linkage](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "l2X6SSTfSWEU",
    "outputId": "011b97e2-ee73-4361-dee0-48e2cc7da666"
   },
   "outputs": [],
   "source": [
    "# different algorithms are good for different applications\n",
    "agglomerative = cluster.AgglomerativeClustering(n_clusters=3, linkage='single')\n",
    "pred = agglomerative.fit_predict(X)\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "zzrjXjRGl-rj",
    "outputId": "34d61f96-e3e7-46a0-b5b0-e87f6939aefc"
   },
   "outputs": [],
   "source": [
    "# different algorithms are good for different applications - kmeans and single agglomerative have so far shown very different results\n",
    "\n",
    "# Create different type of clusters\n",
    "n_samples = 1500\n",
    "X, y = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Run K-Means on non-radial clusters\n",
    "kmeans = cluster.KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "y1_pred = kmeans.predict(X)\n",
    "\n",
    "# Run Agglomerative clustering on non-radial clusters\n",
    "single = cluster.AgglomerativeClustering(n_clusters=2, linkage='single')\n",
    "y2_pred = single.fit_predict(X)\n",
    "\n",
    "# Review results\n",
    "options, charts = plt.subplots(1, 2, figsize=(12, 6))\n",
    "colors = np.array(['blue', 'red'])\n",
    "charts[0].scatter(X[:, 0], X[:, 1], color=colors[y1_pred])\n",
    "charts[1].scatter(X[:, 0], X[:, 1], color=colors[y2_pred])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_3_'></a>[Density-based clustering - DBSCAN](#toc0_)\n",
    "\n",
    "Density-based spatial clustering of applications with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "X, y = datasets.make_moons(n_samples=n_samples, noise=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = cluster.DBSCAN(eps=0.05, min_samples = 5) #change maximum distance and see efect\n",
    "# eps is the maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "# min_samples is the number of samples in a neighborhood for a point to be considered as a core point.\n",
    "\n",
    "pred = dbs.fit_predict(X)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "colors = np.array(['blue', 'red', 'black'])\n",
    "plt.scatter(X[:, 0], X[:, 1], color=colors[pred])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Clustering metrics](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Silhouette Score** [$^{[3]}$](https://www.educative.io/answers/what-is-silhouette-score)\n",
    "\n",
    "> Silhouette Score is a tool for assessing the appropriateness of clustering results by providing a quantitative measure of how well-defined and distinct the clusters are. The Silhouette Score quantifies **how well a data point fits into its assigned cluster** and **how distinct it is from other clusters** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette Score = $\\frac{(b - a)}{max(a, b)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "LKLMgR4bgpMy",
    "outputId": "3701dc2a-aef9-49a0-fe88-c4091d2ea4e3"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Re-create clusters\n",
    "n_samples = 1500\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, centers=3, cluster_std=0.7, n_features=2, random_state=0)\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "pred = kmeans.predict(X)\n",
    "\n",
    "print(\"Model 1 Silhouette Score: {}\".format(silhouette_score(X, pred, metric='euclidean')))\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "AXAoqsPjhHhC",
    "outputId": "a84a1c94-191c-4489-c6b6-32a18308900d"
   },
   "outputs": [],
   "source": [
    "agglomerative = cluster.AgglomerativeClustering(n_clusters=3, linkage='complete')\n",
    "pred = agglomerative.fit_predict(X)\n",
    "\n",
    "print(\"Model 2 Silhouette Score: {}\".format(silhouette_score(X, pred, metric='euclidean')))\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "id": "TmebPqlAhM83",
    "outputId": "4abd74ec-8e2b-409e-f670-be412fc059b2"
   },
   "outputs": [],
   "source": [
    "agglomerative = cluster.AgglomerativeClustering(n_clusters=3, linkage='single')\n",
    "pred = agglomerative.fit_predict(X)\n",
    "\n",
    "print(\"Model 3 Silhouette Score: {}\".format(silhouette_score(X, pred, metric='euclidean')))\n",
    "\n",
    "fig = px.scatter(x=X[:, 0], y=X[:, 1], color=pred, opacity=0.5)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Silhouette Score ranges from -1 to +1. Here is how to interpret the value: [$^{[3]}$](https://www.educative.io/answers/what-is-silhouette-score)\n",
    "\n",
    "**Negative**\n",
    "> A negative score indicates that the **data point is likely assigned to the wrong cluster**, as its distance to its assigned cluster’s points is greater than its distance to the nearest neighboring cluster’s points.\n",
    "\n",
    "**Close to 0**\n",
    "> A score close to 0 implies that the **data point is on or very close to the decision boundary between two clusters**. It indicates that the clustering is not well-defined and can be ambiguous.\n",
    "\n",
    "**Positive**\n",
    "> A positive score indicates that the **data point is appropriately clustered**, and **its distance to its assigned cluster’s points is smaller than its distance to the nearest neighboring cluster’s points**. A score close to +1 suggests that the data point is well-clustered and distinctly separated from other clusters. It is a strong indication of a meaningful clustering result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does the silhouette score fail to be a good measure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1500\n",
    "X, y = datasets.make_moons(n_samples=n_samples, noise=.05)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "kmeans = cluster.KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "y1_pred = kmeans.predict(X)\n",
    "\n",
    "\n",
    "single = cluster.AgglomerativeClustering(n_clusters=2, linkage='single')\n",
    "y2_pred = single.fit_predict(X)\n",
    "\n",
    "\n",
    "options, charts = plt.subplots(1, 2, figsize=(12, 6))\n",
    "colors = np.array(['blue', 'red'])\n",
    "charts[0].scatter(X[:, 0], X[:, 1], color=colors[y1_pred])\n",
    "charts[1].scatter(X[:, 0], X[:, 1], color=colors[y2_pred])\n",
    "plt.show()\n",
    "\n",
    "print(\"Model 1 Silhouette Score: {}\".format(silhouette_score(X, y1_pred)))\n",
    "print(\"Model 2 Silhouette Score: {}\".format(silhouette_score(X, y2_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Resources](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA by StatQuest:\n",
    "- [Main ideas (5 min)](https://www.youtube.com/watch?v=HMOI_lkzW08)\n",
    "- [Step-by-step (22 min)](https://www.youtube.com/watch?v=FgakZw6K1QQ)\n",
    "- [Practical Tips (8 min)](https://www.youtube.com/watch?v=oRvgq966yZg)  \n",
    "\n",
    "[t-SNEs by StatQuest (12 min)](https://www.youtube.com/watch?v=NEaUSP4YerM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[References](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] [What is Silhouette Score, Educative IO](https://www.educative.io/answers/what-is-silhouette-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Acknowledgements](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you, David Henriques, for your awesome lesson structure and content!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lizzy_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
