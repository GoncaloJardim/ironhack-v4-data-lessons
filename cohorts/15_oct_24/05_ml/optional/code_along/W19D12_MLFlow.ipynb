{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f620a4",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[**Introduction to MLFlow and MLOps**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd13b8d",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [**Introduction to MLFlow and MLOps**](#toc1_)    \n",
    "  - [**Why MLFlow?**](#toc1_1_)    \n",
    "  - [**What Can MLFlow Do?**](#toc1_2_)    \n",
    "- [**Hands-On MLFlow**](#toc2_)    \n",
    "  - [**Basic Usage: Autologging**](#toc2_1_)    \n",
    "  - [**Viewing Results Through the UI**](#toc2_2_)    \n",
    "  - [**Creating Experiments and Designing Logic**](#toc2_3_)    \n",
    "  - [**Where Does MLFlow Store Data?**](#toc2_4_)    \n",
    "  - [**Retrieving Models from MLFlow**](#toc2_5_)    \n",
    "  - [**Register models**](#toc2_6_)    \n",
    "  - [**Extra**](#toc2_7_)    \n",
    "    - [**Nested Experiments**](#toc2_7_1_)    \n",
    "    - [**Setting Up AWS Storage**](#toc2_7_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb64df13",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[**Why MLFlow?**](#toc0_)\n",
    "![MLOps](https://raw.githubusercontent.com/dsml-bootcamp-1/nbs-6-master/refs/heads/master/s-601-602/image_ops.png)\n",
    "\n",
    "Machine learning models go through several stages: data preprocessing, training, evaluation, deployment, and monitoring. \n",
    "Ensuring consistency and reproducibility across these stages is a crucial aspect of MLOps (Machine Learning Operations). \n",
    "\n",
    "MLFlow is a tool designed to streamline this process by providing a centralized system to manage and track:\n",
    "- Experiments and their results (e.g., parameters, metrics)\n",
    "- Models and their artifacts (e.g., saved files, plots, images)\n",
    "- Deployment logic for easy retrieval and deployment\n",
    "\n",
    "## <a id='toc1_2_'></a>[**What Can MLFlow Do?**](#toc0_)\n",
    "MLFlow can store:\n",
    "- **Models**: Trained models in various formats (e.g., TensorFlow, PyTorch, Scikit-Learn)\n",
    "- **Parameters**: Hyperparameters used for training\n",
    "- **Metrics**: Evaluation metrics (e.g., accuracy, loss)\n",
    "- **Artifacts**: Additional files (e.g., images, plots, HTML reports)\n",
    "- **Data**: Input and output data (e.g., CSVs, dataframes)\n",
    "\n",
    "![MLFlow Overview](../../../../img/mlflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MLFlow if not already installed\n",
    "# !pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef13c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mlflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc93ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6729eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the version is higher than 1.0.2, then downgrade (needed for autologging)\n",
    "# !pip install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104aa47d",
   "metadata": {},
   "source": [
    "\n",
    "# <a id='toc2_'></a>[**Hands-On MLFlow**](#toc0_)\n",
    "\n",
    "## <a id='toc2_1_'></a>[**Basic Usage: Autologging**](#toc0_)\n",
    "\n",
    "MLFlow provides an easy-to-use `autolog` feature. Let's start by training a simple model and see how MLFlow tracks everything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec423d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import plotly.express as px\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6928ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe0ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X, y split\n",
    "X = data[\"data\"]\n",
    "y = data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab01cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42887156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging for Sklearn\n",
    "mlflow.autolog()\n",
    "\n",
    "# Train a simple model\n",
    "with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "    # Instantiate and fit classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=2)\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf.score(X_test, y_test)\n",
    "\n",
    "    # Add custom metrics - ROC-AUC, PR-AUC\n",
    "    pred_proba = rf.predict_proba(X_test)[:, -1]\n",
    "    mlflow.log_metric(\"test_roc_auc\", roc_auc_score(y_test, pred_proba))\n",
    "\n",
    "    # Can add as many metrics as I want\n",
    "    # mlflow.log_metric(\"test_average_precision\", roc_auc_score(y_test, pred_proba))\n",
    "    # mlflow.log_metric(\"test_roc_auc\", roc_auc_score(y_test, pred_proba))\n",
    "    # mlflow.log_metric(\"test_roc_auc\", roc_auc_score(y_test, pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2f46b",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_2_'></a>[**Viewing Results Through the UI**](#toc0_)\n",
    "\n",
    "Start the MLFlow UI to visualize your logged experiments:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in your terminal (not in Jupyter)\n",
    "# mlflow ui\n",
    "\n",
    "# Can also change the port\n",
    "# mlflow ui --port=8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1d2f",
   "metadata": {},
   "source": [
    "\n",
    "Navigate to `http://localhost:5000` to see your experiments.\n",
    "\n",
    "![MLFlow UI Screenshot](https://mlflow.org/docs/latest/_images/quickstart-our-experiment.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2277eb0",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_3_'></a>[**Creating Experiments and Designing Logic**](#toc0_)\n",
    "You can explicitly create experiments and log data, custom metrics, tags and other artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae064a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set experiment name\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4526848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.create_experiment(name='breast_cancer')\n",
    "mlflow.set_experiment('breast_cancer')\n",
    "mlflow.autolog()\n",
    "\n",
    "# Log parameters, metrics, and artifacts\n",
    "with mlflow.start_run(run_name=\"Random Forest\"):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(pd.DataFrame(X_train, columns=data[\"feature_names\"]), y_train)\n",
    "    \n",
    "    # Set run tags - features, feature_no, data size\n",
    "    mlflow.set_tag(\"features\", data[\"feature_names\"])\n",
    "    mlflow.set_tag(\"null_handling\", None) # keep, fill, drop\n",
    "    mlflow.set_tag(\"feat_selection\", None) # correlation, manual, statistics\n",
    "\n",
    "    # Log predictions\n",
    "    pred_proba = pd.DataFrame(clf.predict_proba(X_test))\n",
    "    mlflow.log_table(pred_proba, artifact_file=\"results/pred_proba.json\")\n",
    "    # mlflow.log_table(pred_proba, artifact_file=\"results/pred_proba_2.csv\")\n",
    "    # mlflow.log_table(pred_proba, artifact_file=\"results/pred_proba_3.xlsx\")\n",
    "\n",
    "    \n",
    "    # Log feature importance plot\n",
    "    # fig = px.bar(x=clf.feature_importances_, y=clf.feature_names_in_)\n",
    "    # mlflow.log_figure(fig, artifact_file=\"plots/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f02a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6988b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049aecf",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_4_'></a>[**Where Does MLFlow Store Data?**](#toc0_)\n",
    "\n",
    "Depending on the backend setup, MLFlow stores data in:\n",
    "- **Local filesystem** (e.g., `./mlruns` directory, suitable for quick tests but slow)\n",
    "- **Local SQLite Database**: Lightweight and easy to set up\n",
    "- **Cloud storage**: AWS S3, Google Cloud Storage, etc., for large-scale deployments\n",
    "\n",
    "To configure MLFlow to use a SQLite backend:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example command to run in terminal (not in Jupyter)\n",
    "# mlflow server/ui \\\n",
    "#    --backend-store-uri sqlite:///mlflow.db \\\n",
    "#    --default-artifact-root ./mlruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911abe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tracking uri\n",
    "mlflow.set_tracking_uri('sqlite:///mlruns.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9b232",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_5_'></a>[**Retrieving Models from MLFlow**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa557085",
   "metadata": {},
   "source": [
    "Search through models - more filtering tips [here](https://mlflow.org/docs/latest/search-runs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f139c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search all runs with PR-AUC higher than 0.7\n",
    "mlflow.search_runs(\n",
    "    experiment_names=[\"breast_cancer\"],\n",
    "    filter_string=\"\"\"\n",
    "    tags.features LIKE '%mean radius%'\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66ca01",
   "metadata": {},
   "source": [
    "You can load previously saved models for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6336cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "from pprint import pprint\n",
    "client = MlflowClient()\n",
    "\n",
    "# Load model\n",
    "latest_version = client.get_latest_versions(\"breast_cancer_tabular\")[0]\n",
    "pprint(latest_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f064c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model using run_id\n",
    "run_id = latest_version.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"  # Replace <run_id> with an actual run ID\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Use the model for predictions\n",
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a73f58",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[**Register models**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658d51a5",
   "metadata": {},
   "source": [
    "This can be done either through the UI or via code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a13578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register model using runs:/ location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf57a9",
   "metadata": {},
   "source": [
    "\n",
    "## <a id='toc2_7_'></a>[**Extra**](#toc0_)\n",
    "\n",
    "### <a id='toc2_7_1_'></a>[**Nested Experiments**](#toc0_)\n",
    "MLFlow allows nested runs for tracking hierarchical experiments. This can be useful if you want to group results from cross-validation folds in separate runs but keep the same attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Create stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nested cross-validation\n",
    "with mlflow.start_run(run_name=\"Random Forest\") as parent_run:\n",
    "    # Log features\n",
    "    \n",
    "    for i, (train_split, test_split) in enumerate(cv_splits):\n",
    "        with mlflow.start_run(run_name=f\"Random Forest {i}\", nested=True):\n",
    "            # New train-test split\n",
    "            \n",
    "            clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Use same logging as before"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc7873e",
   "metadata": {},
   "source": [
    "\n",
    "### <a id='toc2_7_2_'></a>[**Setting Up AWS Storage**](#toc0_)\n",
    "You can configure MLFlow to use AWS Postgresql database (either on RDS or Redshift) as metadata store and AWS S3 as the artifact storage:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in terminal\n",
    "# !mlflow server \\\n",
    "#     --backend-store-uri 'postgresql://user_name:password@link_to_your_aws_postgresql_db:port' \\\n",
    "#     --default-artifact-root s3://your-bucket-name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lizzy_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
